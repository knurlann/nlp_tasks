{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anaphora resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Get the pretrained model of FastText from https://fasttext.cc/docs/en/english-vectors.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) At the pytorch develop a model, that is a feed forward neural network that consists of three layers, an input layer of size 600, a first layer of size 300, a second layer of 80 and an output layer with two units, all layers have regularization and dropout. The activation function on all layers is ReLU"
   ]
  },
  {
   "attachments": {
    "scheme.jpg": {
     "image/jpeg": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![scheme.jpg](attachment:scheme.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = pd.read_csv('gap-development.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is to identify the target of a pronoun within a text passage. The source text is taken from Wikipedia articles. In the dataset, there are labels of the pronoun and two candidate names to which the pronoun could refer. An algorithm should be capable of deciding whether the pronoun refers to name A, name B, or neither.  \n",
    "There are the following columns for analysis:\n",
    "* ID - Unique identifier for an example (Matches to Id in output file format);\n",
    "* Text - Text containing the ambiguous pronoun and two candidate names (about a paragraph in length);\n",
    "* Text - Text containing the ambiguous pronoun and two candidate names (about a paragraph in length);\n",
    "* Pronoun - The target pronoun (text);\n",
    "* Pronoun-offset The character offset of Pronoun in Text;\n",
    "* A - The first name candidate (text);\n",
    "* A-offset - The character offset of name A in Text;\n",
    "* B - The second name candidate;\n",
    "* B-offset - The character offset of name B in Text;\n",
    "* URL - The URL of the source Wikipedia page for the example;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>development-1</td>\n",
       "      <td>Zoe Telford -- played the police officer girlf...</td>\n",
       "      <td>her</td>\n",
       "      <td>274</td>\n",
       "      <td>Cheryl Cassidy</td>\n",
       "      <td>191</td>\n",
       "      <td>True</td>\n",
       "      <td>Pauline</td>\n",
       "      <td>207</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/List_of_Teachers_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>development-2</td>\n",
       "      <td>He grew up in Evanston, Illinois the second ol...</td>\n",
       "      <td>His</td>\n",
       "      <td>284</td>\n",
       "      <td>MacKenzie</td>\n",
       "      <td>228</td>\n",
       "      <td>True</td>\n",
       "      <td>Bernard Leach</td>\n",
       "      <td>251</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Warren_MacKenzie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>development-3</td>\n",
       "      <td>He had been reelected to Congress, but resigne...</td>\n",
       "      <td>his</td>\n",
       "      <td>265</td>\n",
       "      <td>Angeloz</td>\n",
       "      <td>173</td>\n",
       "      <td>False</td>\n",
       "      <td>De la Sota</td>\n",
       "      <td>246</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jos%C3%A9_Manuel_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>development-4</td>\n",
       "      <td>The current members of Crime have also perform...</td>\n",
       "      <td>his</td>\n",
       "      <td>321</td>\n",
       "      <td>Hell</td>\n",
       "      <td>174</td>\n",
       "      <td>False</td>\n",
       "      <td>Henry Rosenthal</td>\n",
       "      <td>336</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Crime_(band)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>development-5</td>\n",
       "      <td>Her Santa Fe Opera debut in 2005 was as Nuria ...</td>\n",
       "      <td>She</td>\n",
       "      <td>437</td>\n",
       "      <td>Kitty Oppenheimer</td>\n",
       "      <td>219</td>\n",
       "      <td>False</td>\n",
       "      <td>Rivera</td>\n",
       "      <td>294</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jessica_Rivera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>development-1996</td>\n",
       "      <td>Faye's third husband, Paul Resnick, reported t...</td>\n",
       "      <td>her</td>\n",
       "      <td>433</td>\n",
       "      <td>Nicole</td>\n",
       "      <td>255</td>\n",
       "      <td>False</td>\n",
       "      <td>Faye</td>\n",
       "      <td>328</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Faye_Resnick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>development-1997</td>\n",
       "      <td>The plot of the film focuses on the life of a ...</td>\n",
       "      <td>her</td>\n",
       "      <td>246</td>\n",
       "      <td>Doris Chu</td>\n",
       "      <td>111</td>\n",
       "      <td>False</td>\n",
       "      <td>Mei</td>\n",
       "      <td>215</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Two_Lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>development-1998</td>\n",
       "      <td>Grant played the part in Trevor Nunn's movie a...</td>\n",
       "      <td>she</td>\n",
       "      <td>348</td>\n",
       "      <td>Maria</td>\n",
       "      <td>259</td>\n",
       "      <td>True</td>\n",
       "      <td>Imelda Staunton</td>\n",
       "      <td>266</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Sir_Andrew_Aguecheek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>development-1999</td>\n",
       "      <td>The fashion house specialised in hand-printed ...</td>\n",
       "      <td>She</td>\n",
       "      <td>284</td>\n",
       "      <td>Helen</td>\n",
       "      <td>145</td>\n",
       "      <td>True</td>\n",
       "      <td>Suzanne Bartsch</td>\n",
       "      <td>208</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Helen_David</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>development-2000</td>\n",
       "      <td>Watkins was a close friend of Hess' first wife...</td>\n",
       "      <td>her</td>\n",
       "      <td>373</td>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>293</td>\n",
       "      <td>False</td>\n",
       "      <td>Watkins</td>\n",
       "      <td>347</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Linda_Watkins</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                                               Text  \\\n",
       "0        development-1  Zoe Telford -- played the police officer girlf...   \n",
       "1        development-2  He grew up in Evanston, Illinois the second ol...   \n",
       "2        development-3  He had been reelected to Congress, but resigne...   \n",
       "3        development-4  The current members of Crime have also perform...   \n",
       "4        development-5  Her Santa Fe Opera debut in 2005 was as Nuria ...   \n",
       "...                ...                                                ...   \n",
       "1995  development-1996  Faye's third husband, Paul Resnick, reported t...   \n",
       "1996  development-1997  The plot of the film focuses on the life of a ...   \n",
       "1997  development-1998  Grant played the part in Trevor Nunn's movie a...   \n",
       "1998  development-1999  The fashion house specialised in hand-printed ...   \n",
       "1999  development-2000  Watkins was a close friend of Hess' first wife...   \n",
       "\n",
       "     Pronoun  Pronoun-offset                  A  A-offset  A-coref  \\\n",
       "0        her             274     Cheryl Cassidy       191     True   \n",
       "1        His             284          MacKenzie       228     True   \n",
       "2        his             265            Angeloz       173    False   \n",
       "3        his             321               Hell       174    False   \n",
       "4        She             437  Kitty Oppenheimer       219    False   \n",
       "...      ...             ...                ...       ...      ...   \n",
       "1995     her             433             Nicole       255    False   \n",
       "1996     her             246          Doris Chu       111    False   \n",
       "1997     she             348              Maria       259     True   \n",
       "1998     She             284              Helen       145     True   \n",
       "1999     her             373          Elizabeth       293    False   \n",
       "\n",
       "                    B  B-offset  B-coref  \\\n",
       "0             Pauline       207    False   \n",
       "1       Bernard Leach       251    False   \n",
       "2          De la Sota       246     True   \n",
       "3     Henry Rosenthal       336     True   \n",
       "4              Rivera       294     True   \n",
       "...               ...       ...      ...   \n",
       "1995             Faye       328     True   \n",
       "1996              Mei       215     True   \n",
       "1997  Imelda Staunton       266    False   \n",
       "1998  Suzanne Bartsch       208    False   \n",
       "1999          Watkins       347     True   \n",
       "\n",
       "                                                    URL  \n",
       "0     http://en.wikipedia.org/wiki/List_of_Teachers_...  \n",
       "1         http://en.wikipedia.org/wiki/Warren_MacKenzie  \n",
       "2     http://en.wikipedia.org/wiki/Jos%C3%A9_Manuel_...  \n",
       "3             http://en.wikipedia.org/wiki/Crime_(band)  \n",
       "4           http://en.wikipedia.org/wiki/Jessica_Rivera  \n",
       "...                                                 ...  \n",
       "1995          http://en.wikipedia.org/wiki/Faye_Resnick  \n",
       "1996              http://en.wikipedia.org/wiki/Two_Lies  \n",
       "1997  http://en.wikipedia.org/wiki/Sir_Andrew_Aguecheek  \n",
       "1998           http://en.wikipedia.org/wiki/Helen_David  \n",
       "1999         http://en.wikipedia.org/wiki/Linda_Watkins  \n",
       "\n",
       "[2000 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Zoe Telford -- played the police officer girlfriend of Simon, Maggie. Dumped by Simon in the final episode of series 1, after he slept with Jenny, and is not seen again. Phoebe Thomas played Cheryl Cassidy, Pauline's friend and also a year 11 pupil in Simon's class. Dumped her boyfriend following Simon's advice after he wouldn't have sex with her but later realised this was due to him catching crabs off her friend Pauline.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.iloc[0]['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_csv('gap-validation.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>validation-1</td>\n",
       "      <td>He admitted making four trips to China and pla...</td>\n",
       "      <td>him</td>\n",
       "      <td>256</td>\n",
       "      <td>Jose de Venecia Jr</td>\n",
       "      <td>208</td>\n",
       "      <td>False</td>\n",
       "      <td>Abalos</td>\n",
       "      <td>241</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Commission_on_Ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>validation-2</td>\n",
       "      <td>Kathleen Nott was born in Camberwell, London. ...</td>\n",
       "      <td>She</td>\n",
       "      <td>185</td>\n",
       "      <td>Ellen</td>\n",
       "      <td>110</td>\n",
       "      <td>False</td>\n",
       "      <td>Kathleen</td>\n",
       "      <td>150</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Kathleen_Nott</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>validation-3</td>\n",
       "      <td>When she returns to her hotel room, a Liberian...</td>\n",
       "      <td>his</td>\n",
       "      <td>435</td>\n",
       "      <td>Jason Scott Lee</td>\n",
       "      <td>383</td>\n",
       "      <td>False</td>\n",
       "      <td>Danny</td>\n",
       "      <td>406</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Hawaii_Five-0_(20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>validation-4</td>\n",
       "      <td>On 19 March 2007, during a campaign appearance...</td>\n",
       "      <td>he</td>\n",
       "      <td>333</td>\n",
       "      <td>Reucassel</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>Debnam</td>\n",
       "      <td>325</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Craig_Reucassel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>validation-5</td>\n",
       "      <td>By this time, Karen Blixen had separated from ...</td>\n",
       "      <td>she</td>\n",
       "      <td>427</td>\n",
       "      <td>Finch Hatton</td>\n",
       "      <td>290</td>\n",
       "      <td>False</td>\n",
       "      <td>Beryl Markham</td>\n",
       "      <td>328</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Denys_Finch_Hatton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>validation-450</td>\n",
       "      <td>He then agrees to name the gargoyle Goldie, af...</td>\n",
       "      <td>He</td>\n",
       "      <td>305</td>\n",
       "      <td>Lucien</td>\n",
       "      <td>252</td>\n",
       "      <td>False</td>\n",
       "      <td>Abel</td>\n",
       "      <td>264</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Goldie_(DC_Comics)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>validation-451</td>\n",
       "      <td>Disgusted with the family's ``mendacity'', Bri...</td>\n",
       "      <td>she</td>\n",
       "      <td>365</td>\n",
       "      <td>Maggie</td>\n",
       "      <td>242</td>\n",
       "      <td>False</td>\n",
       "      <td>Mae</td>\n",
       "      <td>257</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Cat_on_a_Hot_Tin_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>validation-452</td>\n",
       "      <td>She manipulates Michael into giving her custod...</td>\n",
       "      <td>she</td>\n",
       "      <td>306</td>\n",
       "      <td>Scarlett</td>\n",
       "      <td>255</td>\n",
       "      <td>False</td>\n",
       "      <td>Alice</td>\n",
       "      <td>291</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Michael_Moon_(Eas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>validation-453</td>\n",
       "      <td>On April 4, 1986, Donal Henahan wrote in the N...</td>\n",
       "      <td>her</td>\n",
       "      <td>330</td>\n",
       "      <td>Aida</td>\n",
       "      <td>250</td>\n",
       "      <td>False</td>\n",
       "      <td>Miss Millo</td>\n",
       "      <td>294</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Aprile_Millo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>validation-454</td>\n",
       "      <td>Pleasant explains Vassey's guilty conscience m...</td>\n",
       "      <td>him</td>\n",
       "      <td>282</td>\n",
       "      <td>Vassey</td>\n",
       "      <td>234</td>\n",
       "      <td>True</td>\n",
       "      <td>Denton</td>\n",
       "      <td>255</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Small_Crimes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>454 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID                                               Text  \\\n",
       "0      validation-1  He admitted making four trips to China and pla...   \n",
       "1      validation-2  Kathleen Nott was born in Camberwell, London. ...   \n",
       "2      validation-3  When she returns to her hotel room, a Liberian...   \n",
       "3      validation-4  On 19 March 2007, during a campaign appearance...   \n",
       "4      validation-5  By this time, Karen Blixen had separated from ...   \n",
       "..              ...                                                ...   \n",
       "449  validation-450  He then agrees to name the gargoyle Goldie, af...   \n",
       "450  validation-451  Disgusted with the family's ``mendacity'', Bri...   \n",
       "451  validation-452  She manipulates Michael into giving her custod...   \n",
       "452  validation-453  On April 4, 1986, Donal Henahan wrote in the N...   \n",
       "453  validation-454  Pleasant explains Vassey's guilty conscience m...   \n",
       "\n",
       "    Pronoun  Pronoun-offset                   A  A-offset  A-coref  \\\n",
       "0       him             256  Jose de Venecia Jr       208    False   \n",
       "1       She             185               Ellen       110    False   \n",
       "2       his             435     Jason Scott Lee       383    False   \n",
       "3        he             333           Reucassel       300     True   \n",
       "4       she             427        Finch Hatton       290    False   \n",
       "..      ...             ...                 ...       ...      ...   \n",
       "449      He             305              Lucien       252    False   \n",
       "450     she             365              Maggie       242    False   \n",
       "451     she             306            Scarlett       255    False   \n",
       "452     her             330                Aida       250    False   \n",
       "453     him             282              Vassey       234     True   \n",
       "\n",
       "                 B  B-offset  B-coref  \\\n",
       "0           Abalos       241    False   \n",
       "1         Kathleen       150     True   \n",
       "2            Danny       406     True   \n",
       "3           Debnam       325    False   \n",
       "4    Beryl Markham       328     True   \n",
       "..             ...       ...      ...   \n",
       "449           Abel       264    False   \n",
       "450            Mae       257    False   \n",
       "451          Alice       291     True   \n",
       "452     Miss Millo       294     True   \n",
       "453         Denton       255    False   \n",
       "\n",
       "                                                   URL  \n",
       "0    http://en.wikipedia.org/wiki/Commission_on_Ele...  \n",
       "1           http://en.wikipedia.org/wiki/Kathleen_Nott  \n",
       "2    http://en.wikipedia.org/wiki/Hawaii_Five-0_(20...  \n",
       "3         http://en.wikipedia.org/wiki/Craig_Reucassel  \n",
       "4      http://en.wikipedia.org/wiki/Denys_Finch_Hatton  \n",
       "..                                                 ...  \n",
       "449    http://en.wikipedia.org/wiki/Goldie_(DC_Comics)  \n",
       "450  http://en.wikipedia.org/wiki/Cat_on_a_Hot_Tin_...  \n",
       "451  http://en.wikipedia.org/wiki/Michael_Moon_(Eas...  \n",
       "452          http://en.wikipedia.org/wiki/Aprile_Millo  \n",
       "453          http://en.wikipedia.org/wiki/Small_Crimes  \n",
       "\n",
       "[454 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Creating the model\n",
    "## Takes a lot of time depending on the vector file size \n",
    "en_model = KeyedVectors.load_word2vec_format('wiki-news-300d-1M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyAnaphoraNetwork(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=600, out_features=300, bias=True)\n",
      "    (1): Dropout(p=0.3, inplace=False)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=300, out_features=80, bias=True)\n",
      "    (4): Dropout(p=0.3, inplace=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=80, out_features=2, bias=True)\n",
      "    (7): Dropout(p=0.3, inplace=False)\n",
      "    (8): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyAnaphoraNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # define the layers\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(600, 300),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 80),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # forward pass\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "# instantiate the model\n",
    "anmodel = MyAnaphoraNetwork()\n",
    "\n",
    "# print model architecture\n",
    "print(anmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.keyedvectors.Word2VecKeyedVectors"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(en_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_ix = {\"True\": 0, \"False\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = map(float, tokens[1:])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetwiki = load_vectors('wiki-news-300d-1M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNetwork(\n",
      "  (fc1): Linear(in_features=600, out_features=300, bias=True)\n",
      "  (fc2): Linear(in_features=300, out_features=80, bias=True)\n",
      "  (fc3): Linear(in_features=80, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "# define the network class\n",
    "class MyNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        # call constructor from superclass\n",
    "        super().__init__()\n",
    "        \n",
    "        # define network layers\n",
    "        self.fc1 = nn.Linear(600, 300)\n",
    "        self.fc2 = nn.Linear(300, 80)\n",
    "        self.fc3 = nn.Linear(80, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # define forward pass\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# instantiate the model\n",
    "model1 = MyNetwork()\n",
    "\n",
    "# print model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Creating the model\n",
    "## Takes a lot of time depending on the vector file size \n",
    "en_model = KeyedVectors.load_word2vec_format('wiki-news-300d-1M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "entvec = en_model.get_vector('Scott')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all methods\n",
    "# inspect.getmembers(en_model, predicate=inspect.ismethod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sultan/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2150"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = en_model.wv.vocab['Scott'].index\n",
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sultan/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Scott'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_model.wv.index2word[word_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\n|\\r', ' ', text)\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def simple_tokenizer(text, pronoun, candidate_a, candidate_b):\n",
    "    cleantxt = clean_text(text)\n",
    "    txt = []\n",
    "    txt.append(pronoun)\n",
    "    txt.append(candidate_a)\n",
    "    txt.append(candidate_b)\n",
    "    toktxt = tokenize.word_tokenize(cleantxt)\n",
    "    txt = txt + toktxt\n",
    "    \n",
    "    tokenized_text = []\n",
    "    \n",
    "    for word in txt:\n",
    "        try:\n",
    "            word_index = en_model.wv.vocab[word].index\n",
    "            tokenized_text.append(word_index)\n",
    "        except KeyError:\n",
    "            continue\n",
    "            \n",
    "    while len(tokenized_text) < 600:\n",
    "        tokenized_text.append(0)\n",
    "    return tokenized_text\n",
    "\n",
    "\n",
    "\n",
    "def make_target(label, label_to_ix):\n",
    "    return torch.LongTensor([label_to_ix[str(label['A'])], label_to_ix[label[str('B')]]])\n",
    "\n",
    "label_to_ix = {\"True\": 1, \"False\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"zoe telford -- played the police officer girlfriend of simon, maggie. dumped by simon in the final episode of series 1, after he slept with jenny, and is not seen again. phoebe thomas played cheryl cassidy, pauline's friend and also a year 11 pupil in simon's class. dumped her boyfriend following simon's advice after he wouldn't have sex with her but later realised this was due to him catching crabs off her friend pauline.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cltxt = clean_text( df_dev.iloc[0]['Text'])\n",
    "cltxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[8.4000e+01, 1.6050e+04, 2.1190e+05, 7.3744e+05, 1.1400e+02, 6.3600e+02,\n",
      "         1.0000e+00, 4.1400e+02, 1.6520e+03, 6.9720e+03, 4.0000e+00, 9.3425e+04,\n",
      "         0.0000e+00, 1.9319e+05, 2.0000e+00, 1.1639e+04, 2.5000e+01, 9.3425e+04,\n",
      "         6.0000e+00, 1.0000e+00, 8.9300e+02, 1.4350e+03, 4.0000e+00, 4.0700e+02,\n",
      "         1.2000e+02, 0.0000e+00, 7.9000e+01, 5.3000e+01, 1.8794e+04, 1.7000e+01,\n",
      "         1.5284e+05, 0.0000e+00, 3.0000e+00, 1.3000e+01, 3.4000e+01, 5.2600e+02,\n",
      "         1.7700e+02, 2.0000e+00, 1.9901e+05, 7.3344e+04, 6.3600e+02, 1.6757e+05,\n",
      "         4.2160e+05, 0.0000e+00, 5.2525e+05, 2.4000e+01, 1.7540e+03, 3.0000e+00,\n",
      "         6.0000e+01, 7.0000e+00, 1.4400e+02, 1.6700e+02, 1.2437e+04, 6.0000e+00,\n",
      "         9.3425e+04, 2.4000e+01, 5.3700e+02, 2.0000e+00, 1.1639e+04, 8.4000e+01,\n",
      "         8.4860e+03, 2.5900e+02, 9.3425e+04, 2.4000e+01, 1.5390e+03, 7.9000e+01,\n",
      "         5.3000e+01, 8.1000e+01, 3.6000e+01, 1.8140e+03, 1.7000e+01, 8.4000e+01,\n",
      "         4.7000e+01, 2.3900e+02, 9.3200e+03, 2.9000e+01, 2.2000e+01, 9.7100e+02,\n",
      "         5.0000e+00, 1.2300e+02, 9.3510e+03, 2.2856e+04, 2.2000e+02, 8.4000e+01,\n",
      "         1.7540e+03, 5.2525e+05, 2.0000e+00]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sultan/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    }
   ],
   "source": [
    "tokvec = simple_tokenizer(cltxt, 'her', 'Cheryl Cassidy','Pauline')\n",
    "print(len(tokvec))\n",
    "print(tokvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f9e8087a050>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0065, -0.0195, -0.0185,  ..., -0.0335,  0.0307,  0.0059],\n",
      "        [-0.0354, -0.0149, -0.0388,  ..., -0.0234, -0.0210,  0.0384],\n",
      "        [-0.0390,  0.0264,  0.0385,  ...,  0.0403, -0.0346, -0.0186],\n",
      "        ...,\n",
      "        [-0.0029, -0.0401,  0.0057,  ...,  0.0407, -0.0062,  0.0043],\n",
      "        [-0.0119,  0.0062, -0.0186,  ..., -0.0108, -0.0162,  0.0406],\n",
      "        [ 0.0015, -0.0109,  0.0124,  ..., -0.0374, -0.0107, -0.0187]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 2.3963e-02, -3.1093e-02, -4.9145e-03,  7.0923e-03,  3.0068e-02,\n",
      "         3.4195e-02,  2.7411e-02, -3.6295e-03,  3.9245e-03, -9.6981e-04,\n",
      "        -2.6609e-02,  3.4540e-02,  2.2419e-02,  1.0809e-02, -3.1443e-02,\n",
      "        -1.6439e-02,  2.6253e-02, -2.9832e-02,  1.4169e-02,  1.2887e-02,\n",
      "         1.1786e-02,  4.0114e-02, -1.0816e-03, -4.6417e-03, -1.8875e-02,\n",
      "         9.1205e-03, -3.1352e-02, -4.5860e-03, -2.3400e-02,  2.7424e-02,\n",
      "        -2.7339e-02,  3.0018e-02, -5.5317e-03,  2.9077e-02, -3.0674e-02,\n",
      "        -1.1101e-02,  3.2260e-02,  1.8061e-02, -1.2569e-02, -3.8330e-02,\n",
      "        -4.5813e-03,  2.3046e-02,  2.3904e-02, -2.8670e-05,  2.5990e-02,\n",
      "         2.1311e-02, -2.5161e-02,  4.0402e-02, -2.5964e-02, -2.7562e-03,\n",
      "         3.1248e-02,  1.7715e-02, -3.4259e-02,  2.0048e-02,  3.5263e-02,\n",
      "        -4.9293e-03,  1.6632e-02, -1.6904e-02, -3.4950e-02,  9.9635e-03,\n",
      "        -3.4014e-02, -1.9101e-02,  1.6614e-02, -1.4323e-02, -1.2852e-02,\n",
      "        -3.8330e-02, -4.0172e-02,  1.7728e-02,  3.0202e-02, -8.3984e-03,\n",
      "         5.3156e-03, -2.6976e-02,  1.5625e-02, -2.8690e-02, -2.3512e-02,\n",
      "         1.6825e-02, -1.5444e-02, -2.4716e-02,  2.9064e-02,  1.4601e-03,\n",
      "        -1.3619e-02,  3.8999e-02,  3.4816e-02,  2.9585e-02, -3.6662e-02,\n",
      "        -1.4600e-02, -2.5830e-02, -1.9428e-02, -5.0325e-03,  2.6355e-02,\n",
      "        -3.0488e-02, -4.4299e-03, -3.3047e-02, -3.2747e-02,  3.7936e-02,\n",
      "        -2.3523e-02, -7.4379e-03,  3.2909e-02, -2.9913e-02, -3.9239e-02,\n",
      "        -3.1954e-02, -3.7539e-02, -2.5780e-03, -4.5502e-03,  3.8856e-02,\n",
      "        -3.5554e-02,  8.8949e-03, -3.9259e-02, -3.9390e-02,  2.7637e-02,\n",
      "         1.5092e-02, -5.7625e-03, -7.3537e-03, -2.7475e-02,  7.7063e-04,\n",
      "        -1.8732e-02,  2.1054e-02, -6.2510e-03,  3.5363e-02, -2.7482e-02,\n",
      "        -2.6190e-02, -3.9897e-02, -3.8937e-02, -3.2313e-02, -1.3174e-02,\n",
      "         3.9426e-03, -2.2181e-02, -1.3498e-02,  1.8724e-02,  3.0751e-02,\n",
      "        -4.0563e-02, -1.8819e-03, -3.6742e-02,  4.2671e-03,  2.8484e-02,\n",
      "         2.8063e-02, -2.6603e-02,  2.7524e-02,  3.1530e-02, -2.3465e-02,\n",
      "        -4.1472e-03,  3.5555e-02,  2.2187e-02, -9.8664e-03, -2.9201e-02,\n",
      "         1.1928e-02,  3.2772e-02, -1.1772e-02,  1.9854e-02,  1.8842e-02,\n",
      "         4.0147e-02,  2.6008e-02, -4.0764e-02,  1.3133e-02,  3.3779e-02,\n",
      "        -1.8802e-02,  2.7561e-02,  1.7589e-02, -2.2868e-02,  1.4776e-02,\n",
      "         7.3507e-03, -2.0925e-02, -2.8501e-02,  2.7611e-02,  3.9696e-02,\n",
      "         2.2828e-02,  1.8410e-02, -9.1251e-04, -1.6614e-02, -2.8486e-03,\n",
      "        -2.7953e-02,  1.3202e-02, -1.4950e-02,  3.1371e-03, -4.0957e-03,\n",
      "        -9.8727e-03,  8.8859e-04, -1.9519e-02,  3.8962e-02, -2.7810e-02,\n",
      "         4.0635e-02,  2.9301e-02,  2.3362e-02,  2.3964e-02,  1.2315e-03,\n",
      "         4.5078e-03,  8.6192e-03,  4.0778e-02, -1.3588e-02,  9.3414e-03,\n",
      "        -3.1006e-02, -2.8641e-02, -2.3579e-02, -1.0360e-03, -1.7809e-02,\n",
      "        -3.1130e-02,  1.3404e-02, -6.9463e-03,  2.5782e-02,  3.3765e-03,\n",
      "         1.4843e-02,  4.4523e-03, -1.0781e-02,  5.0344e-03,  4.9333e-03,\n",
      "        -6.6157e-03, -4.0016e-02,  1.5065e-02, -1.1894e-02, -1.2312e-02,\n",
      "         5.2476e-03,  6.6538e-03,  2.4521e-02, -4.0485e-03, -2.9479e-02,\n",
      "        -1.0058e-02, -3.3230e-02,  5.2592e-03,  2.8983e-02, -3.2257e-02,\n",
      "         2.0370e-02,  4.0534e-02, -5.3716e-03, -1.2832e-02, -1.8577e-02,\n",
      "         2.0637e-02, -6.4765e-03, -4.0713e-02, -1.7312e-02, -3.8639e-02,\n",
      "         2.2739e-02,  2.6794e-02,  3.2626e-02,  6.3766e-03,  2.4797e-02,\n",
      "        -2.7955e-03, -2.2930e-02,  2.1758e-02,  1.3953e-02,  3.1271e-02,\n",
      "        -3.5042e-02, -1.7342e-02,  5.8983e-03, -2.8557e-02,  3.4748e-02,\n",
      "        -2.5711e-02, -2.0412e-02, -3.3194e-02, -3.1072e-02, -1.3638e-02,\n",
      "        -1.7748e-02, -1.4470e-02, -7.6742e-03,  1.1792e-03,  3.6489e-02,\n",
      "        -1.8362e-02,  3.2640e-02, -1.9640e-02, -7.4814e-03, -3.0194e-02,\n",
      "         2.8738e-02, -2.1842e-02, -1.2258e-02,  2.9816e-02, -2.6145e-02,\n",
      "        -2.2912e-02,  1.1791e-02,  2.7633e-02,  2.8354e-02,  6.6058e-03,\n",
      "        -3.3307e-02, -2.4266e-02, -3.2438e-02,  1.5497e-02,  7.8980e-03,\n",
      "         1.8301e-02,  3.3056e-02,  5.4051e-03,  1.2376e-02, -1.9424e-02,\n",
      "         7.3721e-03,  3.9305e-02,  3.5940e-02,  2.7148e-02,  1.8226e-02,\n",
      "         1.3043e-02,  2.6926e-03,  3.1971e-02, -1.7273e-02,  3.9031e-02,\n",
      "        -2.2939e-03, -7.4372e-03,  1.6739e-02, -3.2699e-02,  1.0536e-02,\n",
      "        -2.1816e-04, -2.0138e-02, -3.1701e-02,  1.4649e-02, -1.0102e-02],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-3.6931e-02, -3.3217e-02, -2.1321e-02,  ...,  1.6211e-02,\n",
      "          2.7837e-02,  7.6833e-03],\n",
      "        [-6.1687e-03, -2.2310e-02,  1.8730e-02,  ...,  4.1541e-02,\n",
      "          2.6102e-02, -1.1705e-02],\n",
      "        [-7.7091e-03,  3.5476e-04, -7.0729e-03,  ..., -1.6828e-02,\n",
      "          5.2843e-02, -4.9402e-02],\n",
      "        ...,\n",
      "        [-2.9604e-02,  1.5771e-02, -3.3989e-02,  ...,  2.5959e-02,\n",
      "          8.7705e-05,  8.6624e-03],\n",
      "        [ 3.7468e-02,  1.7199e-02,  4.5264e-02,  ...,  4.0303e-02,\n",
      "         -2.0385e-03, -2.4708e-02],\n",
      "        [-3.5250e-02, -2.2486e-02,  3.2384e-02,  ...,  4.3476e-02,\n",
      "         -2.9319e-02,  5.1399e-02]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-2.5257e-06,  4.7752e-02, -2.9725e-02, -4.7312e-02, -1.0130e-02,\n",
      "        -1.9014e-02, -3.5085e-02,  1.7644e-02, -3.2718e-02, -5.5320e-02,\n",
      "        -1.8877e-02, -3.3878e-02,  4.1530e-02,  3.8099e-02, -5.1885e-02,\n",
      "        -4.2605e-02,  2.9446e-02,  3.6394e-02,  4.7553e-02,  4.0327e-02,\n",
      "        -3.6342e-02,  7.8495e-03,  5.7150e-02,  1.6077e-02,  4.8951e-02,\n",
      "        -4.5149e-02, -3.6671e-02, -1.4161e-02, -4.9745e-02, -1.1647e-02,\n",
      "        -2.6687e-02, -1.0029e-02,  2.4105e-02,  4.2745e-02, -4.7802e-02,\n",
      "         5.0759e-02, -9.8016e-03, -4.0764e-02, -3.6444e-03,  5.4115e-02,\n",
      "         5.0636e-02,  5.1825e-02,  4.6641e-02,  2.7922e-02, -6.8531e-03,\n",
      "        -6.1119e-03, -2.5169e-02, -2.2957e-02,  3.3419e-02,  4.3361e-02,\n",
      "        -7.1674e-03, -3.6378e-02, -7.9147e-03, -5.6456e-02, -3.2376e-02,\n",
      "         5.2083e-03, -1.0147e-03, -3.1797e-02,  3.6817e-03, -1.9271e-02,\n",
      "        -4.6519e-02, -2.8855e-02,  5.2839e-02,  1.6203e-02, -2.9174e-02,\n",
      "        -5.2216e-02, -1.4315e-03, -2.5341e-02,  2.5388e-02, -5.0722e-02,\n",
      "        -4.0692e-02,  1.7718e-02,  4.6224e-02,  5.1429e-02,  2.1607e-02,\n",
      "         4.2561e-02, -3.7082e-02, -3.6249e-03, -7.0284e-03, -3.9191e-02],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0114, -0.0315,  0.0543,  0.0148, -0.0341, -0.0295, -0.0497,  0.0199,\n",
      "         -0.0514,  0.0335, -0.0096,  0.0145,  0.0689,  0.0987, -0.1017,  0.0608,\n",
      "          0.0850,  0.1008,  0.0414,  0.0624,  0.0239, -0.0007,  0.0924, -0.0616,\n",
      "         -0.0191,  0.0222,  0.0646, -0.0135,  0.0011,  0.0218,  0.0138, -0.0261,\n",
      "         -0.0378, -0.0966, -0.0588,  0.0129,  0.0418, -0.0245, -0.0932, -0.0200,\n",
      "         -0.0409,  0.1097, -0.1073, -0.0929,  0.0310,  0.0687,  0.0517,  0.0056,\n",
      "         -0.1091, -0.0223, -0.0809,  0.0447,  0.0828, -0.0214,  0.0220, -0.1095,\n",
      "         -0.0864,  0.0038, -0.0701,  0.0024, -0.0792,  0.0822, -0.0549,  0.0759,\n",
      "          0.0148,  0.0940, -0.0381,  0.0165, -0.0752,  0.0473, -0.0393,  0.0465,\n",
      "          0.0404,  0.1104, -0.0098, -0.0261,  0.0346,  0.0548,  0.0350, -0.0346],\n",
      "        [ 0.0656,  0.0810,  0.0292,  0.0899,  0.0358,  0.0754, -0.0028,  0.0754,\n",
      "         -0.1105,  0.0912, -0.0418,  0.0875,  0.0170,  0.1049,  0.0923, -0.0164,\n",
      "         -0.1089, -0.0621,  0.0628,  0.0470, -0.0459, -0.0796,  0.0756, -0.0267,\n",
      "         -0.0308,  0.0834,  0.0510, -0.0157, -0.1011, -0.0311,  0.0574,  0.0514,\n",
      "          0.0193,  0.0913, -0.0108, -0.0832,  0.0200, -0.0759, -0.0361, -0.0839,\n",
      "         -0.0527, -0.0273, -0.0927,  0.0449,  0.1016, -0.0057, -0.0650,  0.0813,\n",
      "         -0.0778, -0.0354, -0.0722,  0.1031, -0.0702, -0.0508, -0.0193, -0.0490,\n",
      "         -0.0837, -0.0558, -0.0432,  0.0425,  0.0742,  0.0972, -0.0714, -0.0275,\n",
      "         -0.0705, -0.0649, -0.0969,  0.0637,  0.0539, -0.0229,  0.0333, -0.0034,\n",
      "         -0.0883,  0.1075,  0.0504, -0.0152, -0.0076,  0.0111,  0.0113,  0.0430]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0593, -0.0127], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# the model knows its parameters.  The first output below is A, the second is b.\n",
    "# Whenever you assign a component to a class variable in the __init__ function\n",
    "# of a module, which was done with the line\n",
    "# self.linear = nn.Linear(...)\n",
    "# Then through some Python magic from the PyTorch devs, your module\n",
    "# (in this case, BoWClassifier) will store knowledge of the nn.Linear's parameters\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bow_vector(sentence, word_to_ix):\n",
    "    vec = torch.zeros(len(word_to_ix))\n",
    "    for word in sentence:\n",
    "        vec[word_to_ix[word]] += 1\n",
    "    return vec.view(1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on test data before we train, just to see a before-and-after\n",
    "with torch.no_grad():\n",
    "    for instance, label in test_data:\n",
    "        bow_vec = simple_tokenizer(instance)\n",
    "        log_probs = anmodel(bow_vec)\n",
    "        print(log_probs)\n",
    "\n",
    "# Print the matrix column corresponding to \"creo\"\n",
    "print(next(anmodel.parameters())[:, word_to_ix[\"creo\"]])\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# Usually you want to pass over the training data several times.\n",
    "# 100 is much bigger than on a real data set, but real datasets have more than\n",
    "# two instances.  Usually, somewhere between 5 and 30 epochs is reasonable.\n",
    "for epoch in range(10):\n",
    "    for instance, label in df_dev:\n",
    "        # Step 1. Remember that PyTorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        anmodel.zero_grad()\n",
    "\n",
    "        # Step 2. Make our BOW vector and also we must wrap the target in a\n",
    "        # Tensor as an integer. For example, if the target is SPANISH, then\n",
    "        # we wrap the integer 0. The loss function then knows that the 0th\n",
    "        # element of the log probabilities is the log probability\n",
    "        # corresponding to SPANISH\n",
    "        bow_vec = simple_tokenizer(instance, word_to_ix)\n",
    "        target = make_target(label, label_to_ix)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        log_probs = anmodel(bow_vec)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss = loss_function(log_probs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for instance, label in test_data:\n",
    "        bow_vec = make_bow_vector(instance, word_to_ix)\n",
    "        log_probs = model(bow_vec)\n",
    "        print(log_probs)\n",
    "\n",
    "# Index corresponding to Spanish goes up, English goes down!\n",
    "print(next(model.parameters())[:, word_to_ix[\"creo\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>pr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zoe Telford -- played the police officer girlf...</td>\n",
       "      <td>her</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He grew up in Evanston, Illinois the second ol...</td>\n",
       "      <td>His</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He had been reelected to Congress, but resigne...</td>\n",
       "      <td>his</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The current members of Crime have also perform...</td>\n",
       "      <td>his</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Her Santa Fe Opera debut in 2005 was as Nuria ...</td>\n",
       "      <td>She</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Faye's third husband, Paul Resnick, reported t...</td>\n",
       "      <td>her</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>The plot of the film focuses on the life of a ...</td>\n",
       "      <td>her</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Grant played the part in Trevor Nunn's movie a...</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>The fashion house specialised in hand-printed ...</td>\n",
       "      <td>She</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Watkins was a close friend of Hess' first wife...</td>\n",
       "      <td>her</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    txt   pr\n",
       "0     Zoe Telford -- played the police officer girlf...  her\n",
       "1     He grew up in Evanston, Illinois the second ol...  His\n",
       "2     He had been reelected to Congress, but resigne...  his\n",
       "3     The current members of Crime have also perform...  his\n",
       "4     Her Santa Fe Opera debut in 2005 was as Nuria ...  She\n",
       "...                                                 ...  ...\n",
       "1995  Faye's third husband, Paul Resnick, reported t...  her\n",
       "1996  The plot of the film focuses on the life of a ...  her\n",
       "1997  Grant played the part in Trevor Nunn's movie a...  she\n",
       "1998  The fashion house specialised in hand-printed ...  She\n",
       "1999  Watkins was a close friend of Hess' first wife...  her\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_dev = pd.DataFrame()\n",
    "df_X_dev['txt'] =  df_dev['Text']\n",
    "df_X_dev['pr'] = df_dev['Pronoun']\n",
    "df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoe Telford -- played the police officer girlfriend of Simon, Maggie. Dumped by Simon in the final episode of series 1, after he slept with Jenny, and is not seen again. Phoebe Thomas played Cheryl Cassidy, Pauline's friend and also a year 11 pupil in Simon's class. Dumped her boyfriend following Simon's advice after he wouldn't have sex with her but later realised this was due to him catching crabs off her friend Pauline.\n",
      "He grew up in Evanston, Illinois the second oldest of five children including his brothers, Fred and Gordon and sisters, Marge (Peppy) and Marilyn. His high school days were spent at New Trier High School in Winnetka, Illinois. MacKenzie studied with Bernard Leach from 1949 to 1952. His simple, wheel-thrown functional pottery is heavily influenced by the oriental aesthetic of Shoji Hamada and Kanjiro Kawai.\n",
      "He had been reelected to Congress, but resigned in 1990 to accept a post as Ambassador to Brazil. De la Sota again ran for governor of C*rdoba in 1991. Defeated by Governor Angeloz by over 15%, this latter setback was significant because it cost De la Sota much of his support within the Justicialist Party (which was flush with victory in the 1991 mid-terms), leading to President Carlos Menem 's endorsement of a separate party list in C*rdoba for the 1993 mid-term elections, and to De la Sota's failure to regain a seat in Congress.\n",
      "The current members of Crime have also performed in San Francisco under the band name ''Remote Viewers``. Strike has published two works of fiction in recent years: Ports of Hell, which is listed in the Rock and Roll Hall of Fame Library, and A Loud Humming Sound Came from Above. Rank has produced numerous films (under his real name, Henry Rosenthal) including the hit The Devil and Daniel Johnston.\n",
      "Her Santa Fe Opera debut in 2005 was as Nuria in the revised edition of Golijov's Ainadamar. She sang on the subsequent Deutsche Grammophon recording of the opera. For his opera Doctor Atomic, Adams rewrote the role of Kitty Oppenheimer, originally a mezzo-soprano role, for soprano voice, and Rivera sang the rewritten part of Kitty Oppenheimer at Lyric Opera of Chicago, De Nederlandse Opera, and the Metropolitan Opera., all in 2007. She has since sung several parts and roles in John Adams' works, including the soprano part in El Ni*o, and the role of Kumudha in A Flowering Tree in the Peter Sellars production at the New Crowned Hope Festival in Vienna.\n",
      "Sandra Collins is an American DJ. She got her start on the West Coast of the U.S. in Phoenix, Arizona and into residencies in Los Angeles, and eventually moved towards trance. She used American producers to give herself a unique sound. Collins performed for an estimated 80,000 people on the first night of Woodstock '99, and was the first female DJ featured in the Tranceport series of influential recordings. She recently has released two CD mixes under Paul Oakenfold's Perfecto label.\n",
      "Reb Chaim Yaakov's wife is the sister of Rabbi Moishe Sternbuch, as is the wife of Rabbi Meshulam Dovid Soloveitchik, making the two Rabbis his uncles. Reb Asher's brother Rabbi Shlomo Arieli is the author of a critical edition of the novallae of Rabbi Akiva Eiger. Before his marriage, Rabbi Arieli studied in the Ponevezh Yeshiva headed by Rabbi Shmuel Rozovsky, and he later studied under his father-in-law in the Mirrer Yeshiva.\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for row in df_dev.values:\n",
    "    print(row[1])\n",
    "    if count > 5:\n",
    "        break\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 15])\n"
     ]
    }
   ],
   "source": [
    "print(torch.LongTensor([10,15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 15.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = torch.Tensor([[10,15]])\n",
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\n|\\r', ' ', text)\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def simple_tokenizer(text, pronoun, candidate_a, candidate_b):\n",
    "    \n",
    "    \n",
    "    \n",
    "    cleantxt = clean_text(text)\n",
    "    txt = []\n",
    "    txt.append(pronoun)\n",
    "    txt.append(candidate_a)\n",
    "    txt.append(candidate_b)\n",
    "    toktxt = tokenize.word_tokenize(cleantxt)\n",
    "    txt = txt + toktxt\n",
    "    \n",
    "    tokenized_text = []\n",
    "    \n",
    "    for word in txt:\n",
    "        try:\n",
    "            word_index = en_model.wv.vocab[word].index\n",
    "            tokenized_text.append(word_index)\n",
    "        except KeyError:\n",
    "            continue\n",
    "            \n",
    "    while len(tokenized_text) < 600:\n",
    "        tokenized_text.append(0)\n",
    "    vec = torch.Tensor([tokenized_text])\n",
    "    \n",
    "    return vec.view(1, -1)\n",
    "\n",
    "\n",
    "\n",
    "def make_target(label, label_to_ix):\n",
    "    #print(label_to_ix[str(label['A'])])\n",
    "    #print([label_to_ix[str(label['A'])], label_to_ix[str(label['B'])] ] )\n",
    "    return torch.LongTensor([[ label_to_ix[str(label['A'])], label_to_ix[str(label['B'])] ]])\n",
    "\n",
    "label_to_ix = {\"True\": 1, \"False\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sultan/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-2e90b077515c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_dev\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#row['Text']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mpronoun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#row['Pronoun']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#row['A']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m#row['B']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "#loss_function = nn.NLLLoss()\n",
    "b = nn.MSELoss()\n",
    "a = nn.CrossEntropyLoss()\n",
    "lossfxn = nn.CrossEntropyLoss()\n",
    "lossf = nn.MultiLabelMarginLoss()\n",
    "optimizer = optim.SGD(anmodel.parameters(), lr=0.1)\n",
    "\n",
    "X = df_dev\n",
    "\n",
    "\n",
    "# Usually you want to pass over the training data several times.\n",
    "# 100 is much bigger than on a real data set, but real datasets have more than\n",
    "# two instances.  Usually, somewhere between 5 and 30 epochs is reasonable.\n",
    "for epoch in range(10):\n",
    "    for row in df_dev.values:\n",
    "        txt = row[1] #row['Text']\n",
    "        pronoun = row[2] #row['Pronoun']\n",
    "        ca = row[4] #row['A']\n",
    "        cb = row[7]#row['B']\n",
    "        label = {}\n",
    "        label['A'] = row[6] #row['A-coref']\n",
    "        label['B'] = row[9] #row['B-coref']\n",
    "        \n",
    "        # Step 1. Remember that PyTorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        anmodel.zero_grad()\n",
    "\n",
    "        # Step 2. Make our BOW vector and also we must wrap the target in a\n",
    "        # Tensor as an integer. For example, if the target is SPANISH, then\n",
    "        # we wrap the integer 0. The loss function then knows that the 0th\n",
    "        # element of the log probabilities is the log probability\n",
    "        # corresponding to SPANISH\n",
    "        bow_vec = simple_tokenizer(txt, pronoun, ca, cb)\n",
    "        target = make_target(label, label_to_ix)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Step 3. Run our forward pass.\n",
    "        log_probs = anmodel(bow_vec)\n",
    "        #print('log_probs', log_probs.view(2))\n",
    "        #print('target',target.view(2))\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        #lossf(x, y)\n",
    "        loss = lossf(log_probs, target) #lossfxn(log_probs.view(2), target.view(2))\n",
    "        #print(loss) # outputs tensor(2.4402)\n",
    "        \n",
    "        # loss_a = a(log_probs[0], target[0])\n",
    "        #loss_b = b(log_probs[1], target[1])\n",
    "        #loss = loss_a + loss_b\n",
    "        # loss = loss_function(log_probs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['development-1'\n",
      " \"Zoe Telford -- played the police officer girlfriend of Simon, Maggie. Dumped by Simon in the final episode of series 1, after he slept with Jenny, and is not seen again. Phoebe Thomas played Cheryl Cassidy, Pauline's friend and also a year 11 pupil in Simon's class. Dumped her boyfriend following Simon's advice after he wouldn't have sex with her but later realised this was due to him catching crabs off her friend Pauline.\"\n",
      " 'her' 274 'Cheryl Cassidy' 191 True 'Pauline' 207 False\n",
      " 'http://en.wikipedia.org/wiki/List_of_Teachers_(UK_TV_series)_characters']\n"
     ]
    }
   ],
   "source": [
    "for row in df_dev.values:\n",
    "    print(row)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sultan/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1920e+17, 0.0000e+00]])\n",
      "tensor([[6.9406e+16, 0.0000e+00]])\n",
      "tensor([[5.8091e+15, 0.0000e+00]])\n",
      "tensor([[1.5786e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[9.4432e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.3900e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.3400e+16, 0.0000e+00]])\n",
      "tensor([[1.2789e+16, 0.0000e+00]])\n",
      "tensor([[1.8545e+16, 0.0000e+00]])\n",
      "tensor([[6.4489e+16, 0.0000e+00]])\n",
      "tensor([[1.4049e+17, 0.0000e+00]])\n",
      "tensor([[1.8413e+15, 0.0000e+00]])\n",
      "tensor([[1.2483e+16, 0.0000e+00]])\n",
      "tensor([[1.8523e+16, 0.0000e+00]])\n",
      "tensor([[6.5150e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.6480e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.3667e+15, 0.0000e+00]])\n",
      "tensor([[3.2680e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.4953e+17, 0.0000e+00]])\n",
      "tensor([[4.9454e+15, 0.0000e+00]])\n",
      "tensor([[2.4062e+15, 0.0000e+00]])\n",
      "tensor([[3.6165e+15, 0.0000e+00]])\n",
      "tensor([[5.6978e+15, 0.0000e+00]])\n",
      "tensor([[8.9094e+15, 0.0000e+00]])\n",
      "tensor([[2.5903e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.7362e+14, 0.0000e+00]])\n",
      "tensor([[1.3896e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[6.9342e+15, 0.0000e+00]])\n",
      "tensor([[3.1680e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.8877e+16, 0.0000e+00]])\n",
      "tensor([[4.3130e+15, 0.0000e+00]])\n",
      "tensor([[7.0041e+16, 0.0000e+00]])\n",
      "tensor([[4.1912e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.4445e+15, 0.0000e+00]])\n",
      "tensor([[1.7567e+16, 0.0000e+00]])\n",
      "tensor([[9.4738e+15, 0.0000e+00]])\n",
      "tensor([[1.3717e+17, 0.0000e+00]])\n",
      "tensor([[5.4031e+16, 0.0000e+00]])\n",
      "tensor([[9.1025e+15, 0.0000e+00]])\n",
      "tensor([[6.8816e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.0037e+15, 0.0000e+00]])\n",
      "tensor([[4.1331e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.1390e+16, 0.0000e+00]])\n",
      "tensor([[5.0890e+15, 0.0000e+00]])\n",
      "tensor([[2.7398e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[7.7567e+15, 0.0000e+00]])\n",
      "tensor([[3.0319e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.2272e+15, 0.0000e+00]])\n",
      "tensor([[4.3174e+16, 0.0000e+00]])\n",
      "tensor([[4.7490e+15, 0.0000e+00]])\n",
      "tensor([[9.8471e+15, 0.0000e+00]])\n",
      "tensor([[1.2849e+16, 0.0000e+00]])\n",
      "tensor([[4.2273e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.7828e+16, 0.0000e+00]])\n",
      "tensor([[9.0365e+15, 0.0000e+00]])\n",
      "tensor([[8.3023e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[8.0695e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.0930e+15, 0.0000e+00]])\n",
      "tensor([[2.5032e+15, 0.0000e+00]])\n",
      "tensor([[4.8733e+16, 0.0000e+00]])\n",
      "tensor([[2.4776e+15, 0.0000e+00]])\n",
      "tensor([[5.4119e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.5694e+16, 0.0000e+00]])\n",
      "tensor([[9.9413e+15, 0.0000e+00]])\n",
      "tensor([[5.2923e+16, 0.0000e+00]])\n",
      "tensor([[4.6849e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.5167e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.2725e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.6987e+16, 0.0000e+00]])\n",
      "tensor([[1.5802e+15, 0.0000e+00]])\n",
      "tensor([[1.7547e+16, 0.0000e+00]])\n",
      "tensor([[3.8120e+16, 0.0000e+00]])\n",
      "tensor([[6.9372e+15, 0.0000e+00]])\n",
      "tensor([[8.6498e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.7859e+16, 0.0000e+00]])\n",
      "tensor([[2.4187e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.2551e+15, 0.0000e+00]])\n",
      "tensor([[2.6675e+15, 0.0000e+00]])\n",
      "tensor([[2.7697e+16, 0.0000e+00]])\n",
      "tensor([[5.8132e+15, 0.0000e+00]])\n",
      "tensor([[7.0897e+14, 0.0000e+00]])\n",
      "tensor([[2.1901e+15, 0.0000e+00]])\n",
      "tensor([[2.9944e+15, 0.0000e+00]])\n",
      "tensor([[4.1530e+15, 0.0000e+00]])\n",
      "tensor([[1.5117e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.9760e+16, 0.0000e+00]])\n",
      "tensor([[7.4311e+14, 0.0000e+00]])\n",
      "tensor([[3.9337e+16, 0.0000e+00]])\n",
      "tensor([[1.0310e+15, 0.0000e+00]])\n",
      "tensor([[2.2788e+16, 0.0000e+00]])\n",
      "tensor([[3.4240e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.9453e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.5520e+15, 0.0000e+00]])\n",
      "tensor([[1.8980e+15, 0.0000e+00]])\n",
      "tensor([[9.9139e+15, 0.0000e+00]])\n",
      "tensor([[2.8550e+16, 0.0000e+00]])\n",
      "tensor([[1.1676e+17, 0.0000e+00]])\n",
      "tensor([[1.8126e+15, 0.0000e+00]])\n",
      "tensor([[1.0747e+16, 0.0000e+00]])\n",
      "tensor([[9.1149e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[8.8687e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.1748e+16, 0.0000e+00]])\n",
      "tensor([[7.0451e+14, 0.0000e+00]])\n",
      "tensor([[1.4459e+16, 0.0000e+00]])\n",
      "tensor([[1.7538e+15, 0.0000e+00]])\n",
      "tensor([[1.4862e+15, 0.0000e+00]])\n",
      "tensor([[1.7276e+15, 0.0000e+00]])\n",
      "tensor([[2.9232e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.5874e+16, 0.0000e+00]])\n",
      "tensor([[8.3358e+14, 0.0000e+00]])\n",
      "tensor([[1.3697e+15, 0.0000e+00]])\n",
      "tensor([[1.3960e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[6.4935e+14, 0.0000e+00]])\n",
      "tensor([[1.9871e+15, 0.0000e+00]])\n",
      "tensor([[6.9904e+14, 0.0000e+00]])\n",
      "tensor([[5.9740e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.5207e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.8224e+15, 0.0000e+00]])\n",
      "tensor([[4.5798e+16, 0.0000e+00]])\n",
      "tensor([[8.8130e+15, 0.0000e+00]])\n",
      "tensor([[2.0383e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.7475e+15, 0.0000e+00]])\n",
      "tensor([[8.4433e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.3288e+15, 0.0000e+00]])\n",
      "tensor([[1.2159e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.4798e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.5806e+15, 0.0000e+00]])\n",
      "tensor([[5.1618e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.0110e+16, 0.0000e+00]])\n",
      "tensor([[2.1790e+16, 0.0000e+00]])\n",
      "tensor([[8.1293e+15, 0.0000e+00]])\n",
      "tensor([[1.5303e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.5178e+15, 0.0000e+00]])\n",
      "tensor([[7.2915e+14, 0.0000e+00]])\n",
      "tensor([[2.8403e+15, 0.0000e+00]])\n",
      "tensor([[1.5944e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.0726e+15, 0.0000e+00]])\n",
      "tensor([[4.1319e+15, 0.0000e+00]])\n",
      "tensor([[7.5053e+14, 0.0000e+00]])\n",
      "tensor([[1.1232e+15, 0.0000e+00]])\n",
      "tensor([[1.2843e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.3813e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.9863e+16, 0.0000e+00]])\n",
      "tensor([[3.4891e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.5774e+15, 0.0000e+00]])\n",
      "tensor([[9.9305e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.6831e+15, 0.0000e+00]])\n",
      "tensor([[1.0160e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.0350e+15, 0.0000e+00]])\n",
      "tensor([[1.2875e+17, 0.0000e+00]])\n",
      "tensor([[6.5616e+14, 0.0000e+00]])\n",
      "tensor([[1.5321e+17, 0.0000e+00]])\n",
      "tensor([[3.6839e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[6.1677e+14, 0.0000e+00]])\n",
      "tensor([[1.9263e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.4693e+16, 0.0000e+00]])\n",
      "tensor([[4.6940e+15, 0.0000e+00]])\n",
      "tensor([[5.1874e+13, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.6206e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.5856e+16, 0.0000e+00]])\n",
      "tensor([[2.2208e+14, 0.0000e+00]])\n",
      "tensor([[4.6675e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.6525e+16, 0.0000e+00]])\n",
      "tensor([[1.0186e+17, 0.0000e+00]])\n",
      "tensor([[5.2345e+16, 0.0000e+00]])\n",
      "tensor([[1.0453e+15, 0.0000e+00]])\n",
      "tensor([[2.8978e+16, 0.0000e+00]])\n",
      "tensor([[2.5650e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.2421e+15, 0.0000e+00]])\n",
      "tensor([[1.6707e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.1363e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.1893e+16, 0.0000e+00]])\n",
      "tensor([[1.6811e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.2179e+16, 0.0000e+00]])\n",
      "tensor([[1.4276e+16, 0.0000e+00]])\n",
      "tensor([[2.9227e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.7674e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.5022e+15, 0.0000e+00]])\n",
      "tensor([[3.4162e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[6.4967e+15, 0.0000e+00]])\n",
      "tensor([[5.0414e+13, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.6889e+15, 0.0000e+00]])\n",
      "tensor([[1.0020e+15, 0.0000e+00]])\n",
      "tensor([[7.2479e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.0882e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.4465e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.5222e+16, 0.0000e+00]])\n",
      "tensor([[6.2859e+15, 0.0000e+00]])\n",
      "tensor([[9.3040e+14, 0.0000e+00]])\n",
      "tensor([[1.1754e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.2181e+16, 0.0000e+00]])\n",
      "tensor([[3.0616e+16, 0.0000e+00]])\n",
      "tensor([[6.3922e+15, 0.0000e+00]])\n",
      "tensor([[6.7895e+15, 0.0000e+00]])\n",
      "tensor([[8.6382e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[8.3764e+15, 0.0000e+00]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.]])\n",
      "tensor([[1.1581e+17, 0.0000e+00]])\n",
      "tensor([[1.6016e+16, 0.0000e+00]])\n",
      "tensor([[1.5000e+16, 0.0000e+00]])\n",
      "tensor([[1.5485e+15, 0.0000e+00]])\n",
      "tensor([[2.3306e+15, 0.0000e+00]])\n",
      "tensor([[1.8772e+16, 0.0000e+00]])\n",
      "tensor([[2.9254e+16, 0.0000e+00]])\n",
      "tensor([[1.1540e+16, 0.0000e+00]])\n",
      "tensor([[2.3523e+16, 0.0000e+00]])\n",
      "tensor([[2.2726e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[6.0906e+15, 0.0000e+00]])\n",
      "tensor([[4.3848e+15, 0.0000e+00]])\n",
      "tensor([[3.3289e+15, 0.0000e+00]])\n",
      "tensor([[6.0208e+15, 0.0000e+00]])\n",
      "tensor([[3.7030e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[7.6783e+16, 0.0000e+00]])\n",
      "tensor([[6.7556e+15, 0.0000e+00]])\n",
      "tensor([[1.5919e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.6237e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[9.4591e+15, 0.0000e+00]])\n",
      "tensor([[5.3701e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[7.7707e+15, 0.0000e+00]])\n",
      "tensor([[9.8167e+14, 0.0000e+00]])\n",
      "tensor([[4.9559e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[8.3099e+15, 0.0000e+00]])\n",
      "tensor([[1.6050e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.2882e+15, 0.0000e+00]])\n",
      "tensor([[3.5345e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[9.8369e+14, 0.0000e+00]])\n",
      "tensor([[4.6055e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.4609e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.0485e+16, 0.0000e+00]])\n",
      "tensor([[3.6218e+15, 0.0000e+00]])\n",
      "tensor([[4.2253e+16, 0.0000e+00]])\n",
      "tensor([[1.5158e+16, 0.0000e+00]])\n",
      "tensor([[2.2098e+17, 0.0000e+00]])\n",
      "tensor([[4.0636e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.1652e+16, 0.0000e+00]])\n",
      "tensor([[1.5747e+17, 0.0000e+00]])\n",
      "tensor([[2.4685e+17, 0.0000e+00]])\n",
      "tensor([[1.5428e+16, 0.0000e+00]])\n",
      "tensor([[1.1236e+16, 0.0000e+00]])\n",
      "tensor([[1.1307e+15, 0.0000e+00]])\n",
      "tensor([[6.0715e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[6.9804e+15, 0.0000e+00]])\n",
      "tensor([[1.9287e+16, 0.0000e+00]])\n",
      "tensor([[2.1617e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.0399e+17, 0.0000e+00]])\n",
      "tensor([[6.6529e+15, 0.0000e+00]])\n",
      "tensor([[2.0912e+16, 0.0000e+00]])\n",
      "tensor([[1.6549e+17, 0.0000e+00]])\n",
      "tensor([[4.2202e+16, 0.0000e+00]])\n",
      "tensor([[6.9526e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.3890e+15, 0.0000e+00]])\n",
      "tensor([[7.9088e+15, 0.0000e+00]])\n",
      "tensor([[1.8393e+16, 0.0000e+00]])\n",
      "tensor([[3.7066e+14, 0.0000e+00]])\n",
      "tensor([[1.1722e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.0498e+17, 0.0000e+00]])\n",
      "tensor([[2.6438e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.9318e+15, 0.0000e+00]])\n",
      "tensor([[7.1951e+16, 0.0000e+00]])\n",
      "tensor([[3.3715e+15, 0.0000e+00]])\n",
      "tensor([[1.5465e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.2836e+17, 0.0000e+00]])\n",
      "tensor([[2.1722e+15, 0.0000e+00]])\n",
      "tensor([[1.4229e+16, 0.0000e+00]])\n",
      "tensor([[1.1208e+17, 0.0000e+00]])\n",
      "tensor([[1.3755e+16, 0.0000e+00]])\n",
      "tensor([[4.0728e+15, 0.0000e+00]])\n",
      "tensor([[1.3096e+17, 0.0000e+00]])\n",
      "tensor([[8.9105e+16, 0.0000e+00]])\n",
      "tensor([[8.4748e+15, 0.0000e+00]])\n",
      "tensor([[1.6112e+15, 0.0000e+00]])\n",
      "tensor([[4.1085e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[9.2966e+15, 0.0000e+00]])\n",
      "tensor([[1.4417e+17, 0.0000e+00]])\n",
      "tensor([[6.1572e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.0085e+15, 0.0000e+00]])\n",
      "tensor([[2.5687e+15, 0.0000e+00]])\n",
      "tensor([[7.1043e+15, 0.0000e+00]])\n",
      "tensor([[1.2703e+16, 0.0000e+00]])\n",
      "tensor([[3.5364e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.8250e+14, 0.0000e+00]])\n",
      "tensor([[9.3847e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.4155e+16, 0.0000e+00]])\n",
      "tensor([[1.2246e+15, 0.0000e+00]])\n",
      "tensor([[3.7954e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.9717e+17, 0.0000e+00]])\n",
      "tensor([[1.0925e+15, 0.0000e+00]])\n",
      "tensor([[9.1092e+14, 0.0000e+00]])\n",
      "tensor([[3.5961e+15, 0.0000e+00]])\n",
      "tensor([[1.3455e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[9.4659e+15, 0.0000e+00]])\n",
      "tensor([[2.7867e+16, 0.0000e+00]])\n",
      "tensor([[2.4666e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[8.3482e+15, 0.0000e+00]])\n",
      "tensor([[4.4465e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[6.4919e+16, 0.0000e+00]])\n",
      "tensor([[1.3889e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[8.0226e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[8.3411e+15, 0.0000e+00]])\n",
      "tensor([[1.0962e+17, 0.0000e+00]])\n",
      "tensor([[4.5820e+15, 0.0000e+00]])\n",
      "tensor([[1.3727e+15, 0.0000e+00]])\n",
      "tensor([[1.3265e+15, 0.0000e+00]])\n",
      "tensor([[4.4916e+15, 0.0000e+00]])\n",
      "tensor([[6.3193e+16, 0.0000e+00]])\n",
      "tensor([[2.8821e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.1227e+16, 0.0000e+00]])\n",
      "tensor([[8.4542e+16, 0.0000e+00]])\n",
      "tensor([[1.2903e+15, 0.0000e+00]])\n",
      "tensor([[2.7727e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[6.5691e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.5374e+15, 0.0000e+00]])\n",
      "tensor([[2.6524e+16, 0.0000e+00]])\n",
      "tensor([[1.1664e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[9.2502e+15, 0.0000e+00]])\n",
      "tensor([[3.6795e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.2743e+15, 0.0000e+00]])\n",
      "tensor([[6.6364e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.1225e+15, 0.0000e+00]])\n",
      "tensor([[2.3782e+15, 0.0000e+00]])\n",
      "tensor([[5.2038e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[7.4134e+15, 0.0000e+00]])\n",
      "tensor([[3.5844e+15, 0.0000e+00]])\n",
      "tensor([[1.2056e+16, 0.0000e+00]])\n",
      "tensor([[5.6146e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.0755e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.7918e+16, 0.0000e+00]])\n",
      "tensor([[2.0371e+16, 0.0000e+00]])\n",
      "tensor([[3.9791e+16, 0.0000e+00]])\n",
      "tensor([[9.0078e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.4240e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[9.6320e+15, 0.0000e+00]])\n",
      "tensor([[4.2551e+14, 0.0000e+00]])\n",
      "tensor([[1.9301e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.3353e+15, 0.0000e+00]])\n",
      "tensor([[8.3066e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.6128e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.5549e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.7659e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[7.8678e+14, 0.0000e+00]])\n",
      "tensor([[4.2667e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.0241e+15, 0.0000e+00]])\n",
      "tensor([[1.4434e+15, 0.0000e+00]])\n",
      "tensor([[1.1188e+16, 0.0000e+00]])\n",
      "tensor([[9.3416e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.1820e+15, 0.0000e+00]])\n",
      "tensor([[1.7712e+16, 0.0000e+00]])\n",
      "tensor([[2.3765e+15, 0.0000e+00]])\n",
      "tensor([[1.6482e+16, 0.0000e+00]])\n",
      "tensor([[2.8083e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.7406e+15, 0.0000e+00]])\n",
      "tensor([[3.3277e+16, 0.0000e+00]])\n",
      "tensor([[8.6682e+15, 0.0000e+00]])\n",
      "tensor([[9.9586e+15, 0.0000e+00]])\n",
      "tensor([[9.0433e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.6061e+17, 0.0000e+00]])\n",
      "tensor([[3.0418e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.1695e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.7151e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.9563e+15, 0.0000e+00]])\n",
      "tensor([[2.7053e+15, 0.0000e+00]])\n",
      "tensor([[6.4804e+15, 0.0000e+00]])\n",
      "tensor([[1.1317e+17, 0.0000e+00]])\n",
      "tensor([[1.9707e+16, 0.0000e+00]])\n",
      "tensor([[2.5749e+15, 0.0000e+00]])\n",
      "tensor([[1.9581e+16, 0.0000e+00]])\n",
      "tensor([[5.0542e+15, 0.0000e+00]])\n",
      "tensor([[3.2819e+15, 0.0000e+00]])\n",
      "tensor([[2.2016e+16, 0.0000e+00]])\n",
      "tensor([[7.1937e+16, 0.0000e+00]])\n",
      "tensor([[7.7462e+15, 0.0000e+00]])\n",
      "tensor([[4.2041e+15, 0.0000e+00]])\n",
      "tensor([[3.4962e+15, 0.0000e+00]])\n",
      "tensor([[7.5171e+14, 0.0000e+00]])\n",
      "tensor([[3.1318e+16, 0.0000e+00]])\n",
      "tensor([[9.9335e+14, 0.0000e+00]])\n",
      "tensor([[7.5631e+14, 0.0000e+00]])\n",
      "tensor([[1.3045e+16, 0.0000e+00]])\n",
      "tensor([[2.0649e+16, 0.0000e+00]])\n",
      "tensor([[5.2409e+16, 0.0000e+00]])\n",
      "tensor([[1.6487e+16, 0.0000e+00]])\n",
      "tensor([[1.1206e+16, 0.0000e+00]])\n",
      "tensor([[2.7705e+15, 0.0000e+00]])\n",
      "tensor([[3.7410e+15, 0.0000e+00]])\n",
      "tensor([[5.4264e+14, 0.0000e+00]])\n",
      "tensor([[2.1203e+17, 0.0000e+00]])\n",
      "tensor([[5.2157e+15, 0.0000e+00]])\n",
      "tensor([[2.3076e+16, 0.0000e+00]])\n",
      "tensor([[4.5607e+15, 0.0000e+00]])\n",
      "tensor([[3.6291e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.9290e+15, 0.0000e+00]])\n",
      "tensor([[2.3583e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.2953e+16, 0.0000e+00]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.3224e+16, 0.0000e+00]])\n",
      "tensor([[1.8132e+15, 0.0000e+00]])\n",
      "tensor([[4.4490e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.3094e+15, 0.0000e+00]])\n",
      "tensor([[2.8159e+17, 0.0000e+00]])\n",
      "tensor([[1.9775e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[7.6133e+15, 0.0000e+00]])\n",
      "tensor([[2.5898e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[6.5881e+15, 0.0000e+00]])\n",
      "tensor([[7.3045e+15, 0.0000e+00]])\n",
      "tensor([[1.3681e+15, 0.0000e+00]])\n",
      "tensor([[1.6548e+16, 0.0000e+00]])\n",
      "tensor([[2.3436e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.2389e+17, 0.0000e+00]])\n",
      "tensor([[1.3582e+16, 0.0000e+00]])\n",
      "tensor([[5.6295e+15, 0.0000e+00]])\n",
      "tensor([[3.5216e+15, 0.0000e+00]])\n",
      "tensor([[9.2662e+16, 0.0000e+00]])\n",
      "tensor([[1.4128e+16, 0.0000e+00]])\n",
      "tensor([[3.4464e+16, 0.0000e+00]])\n",
      "tensor([[6.6463e+15, 0.0000e+00]])\n",
      "tensor([[1.7129e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.6873e+15, 0.0000e+00]])\n",
      "tensor([[4.1225e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.6817e+15, 0.0000e+00]])\n",
      "tensor([[1.8329e+16, 0.0000e+00]])\n",
      "tensor([[1.1385e+16, 0.0000e+00]])\n",
      "tensor([[4.5483e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.6340e+16, 0.0000e+00]])\n",
      "tensor([[6.9721e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.7530e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.0611e+15, 0.0000e+00]])\n",
      "tensor([[2.1904e+15, 0.0000e+00]])\n",
      "tensor([[9.0043e+14, 0.0000e+00]])\n",
      "tensor([[3.0156e+15, 0.0000e+00]])\n",
      "tensor([[1.0872e+16, 0.0000e+00]])\n",
      "tensor([[2.3198e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[8.0609e+15, 0.0000e+00]])\n",
      "tensor([[5.1663e+15, 0.0000e+00]])\n",
      "tensor([[1.1370e+17, 0.0000e+00]])\n",
      "tensor([[3.6475e+16, 0.0000e+00]])\n",
      "tensor([[6.0305e+16, 0.0000e+00]])\n",
      "tensor([[5.3302e+15, 0.0000e+00]])\n",
      "tensor([[1.8842e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.6009e+16, 0.0000e+00]])\n",
      "tensor([[1.8539e+16, 0.0000e+00]])\n",
      "tensor([[1.3973e+16, 0.0000e+00]])\n",
      "tensor([[1.8121e+16, 0.0000e+00]])\n",
      "tensor([[3.2306e+15, 0.0000e+00]])\n",
      "tensor([[1.6982e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.4221e+14, 0.0000e+00]])\n",
      "tensor([[6.0957e+16, 0.0000e+00]])\n",
      "tensor([[1.7136e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.6454e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.7862e+15, 0.0000e+00]])\n",
      "tensor([[3.8184e+16, 0.0000e+00]])\n",
      "tensor([[2.3834e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.0434e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.1745e+16, 0.0000e+00]])\n",
      "tensor([[1.1190e+16, 0.0000e+00]])\n",
      "tensor([[3.0458e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.4477e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.6122e+15, 0.0000e+00]])\n",
      "tensor([[1.7113e+16, 0.0000e+00]])\n",
      "tensor([[3.8513e+15, 0.0000e+00]])\n",
      "tensor([[1.3107e+15, 0.0000e+00]])\n",
      "tensor([[8.3499e+16, 0.0000e+00]])\n",
      "tensor([[2.3405e+15, 0.0000e+00]])\n",
      "tensor([[8.6034e+15, 0.0000e+00]])\n",
      "tensor([[2.3250e+16, 0.0000e+00]])\n",
      "tensor([[2.4712e+15, 0.0000e+00]])\n",
      "tensor([[1.4954e+16, 0.0000e+00]])\n",
      "tensor([[6.0681e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.4272e+15, 0.0000e+00]])\n",
      "tensor([[2.2526e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.0072e+15, 0.0000e+00]])\n",
      "tensor([[1.8778e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[9.9630e+15, 0.0000e+00]])\n",
      "tensor([[3.5196e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.0851e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.2812e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.4366e+14, 0.0000e+00]])\n",
      "tensor([[2.7030e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[7.3806e+15, 0.0000e+00]])\n",
      "tensor([[4.2482e+16, 0.0000e+00]])\n",
      "tensor([[1.6372e+15, 0.0000e+00]])\n",
      "tensor([[7.2265e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.7833e+16, 0.0000e+00]])\n",
      "tensor([[9.9464e+14, 0.0000e+00]])\n",
      "tensor([[1.9404e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.7744e+15, 0.0000e+00]])\n",
      "tensor([[2.0310e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.2299e+16, 0.0000e+00]])\n",
      "tensor([[8.0073e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.5014e+16, 0.0000e+00]])\n",
      "tensor([[8.3717e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[6.3459e+16, 0.0000e+00]])\n",
      "tensor([[1.3203e+15, 0.0000e+00]])\n",
      "tensor([[3.8372e+15, 0.0000e+00]])\n",
      "tensor([[3.2253e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.0131e+16, 0.0000e+00]])\n",
      "tensor([[5.0049e+15, 0.0000e+00]])\n",
      "tensor([[6.1862e+16, 0.0000e+00]])\n",
      "tensor([[3.7210e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.4997e+16, 0.0000e+00]])\n",
      "tensor([[2.6437e+15, 0.0000e+00]])\n",
      "tensor([[1.1912e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.8882e+15, 0.0000e+00]])\n",
      "tensor([[4.7754e+14, 0.0000e+00]])\n",
      "tensor([[1.3610e+15, 0.0000e+00]])\n",
      "tensor([[5.4923e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.2877e+15, 0.0000e+00]])\n",
      "tensor([[1.3915e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.8314e+15, 0.0000e+00]])\n",
      "tensor([[9.0245e+14, 0.0000e+00]])\n",
      "tensor([[2.0941e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.9763e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.2195e+15, 0.0000e+00]])\n",
      "tensor([[1.8075e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.6236e+14, 0.0000e+00]])\n",
      "tensor([[3.1427e+15, 0.0000e+00]])\n",
      "tensor([[1.5992e+16, 0.0000e+00]])\n",
      "tensor([[6.1858e+15, 0.0000e+00]])\n",
      "tensor([[2.0898e+15, 0.0000e+00]])\n",
      "tensor([[8.4124e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.2892e+16, 0.0000e+00]])\n",
      "tensor([[8.3290e+15, 0.0000e+00]])\n",
      "tensor([[7.3190e+14, 0.0000e+00]])\n",
      "tensor([[5.2765e+16, 0.0000e+00]])\n",
      "tensor([[3.7904e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.9749e+15, 0.0000e+00]])\n",
      "tensor([[1.4945e+15, 0.0000e+00]])\n",
      "tensor([[1.3942e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.7066e+15, 0.0000e+00]])\n",
      "tensor([[5.8631e+16, 0.0000e+00]])\n",
      "tensor([[1.9113e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.9491e+16, 0.0000e+00]])\n",
      "tensor([[5.6367e+15, 0.0000e+00]])\n",
      "tensor([[1.1942e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[8.6842e+14, 0.0000e+00]])\n",
      "tensor([[6.0578e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[6.5195e+15, 0.0000e+00]])\n",
      "tensor([[3.1811e+14, 0.0000e+00]])\n",
      "tensor([[8.1230e+15, 0.0000e+00]])\n",
      "tensor([[5.0837e+15, 0.0000e+00]])\n",
      "tensor([[6.5610e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.0314e+16, 0.0000e+00]])\n",
      "tensor([[5.2410e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.0185e+16, 0.0000e+00]])\n",
      "tensor([[2.0301e+15, 0.0000e+00]])\n",
      "tensor([[6.4043e+15, 0.0000e+00]])\n",
      "tensor([[5.8333e+15, 0.0000e+00]])\n",
      "tensor([[8.2069e+15, 0.0000e+00]])\n",
      "tensor([[2.5948e+16, 0.0000e+00]])\n",
      "tensor([[2.9360e+16, 0.0000e+00]])\n",
      "tensor([[3.8359e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.6361e+16, 0.0000e+00]])\n",
      "tensor([[1.9093e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.9456e+16, 0.0000e+00]])\n",
      "tensor([[8.8742e+15, 0.0000e+00]])\n",
      "tensor([[4.5066e+15, 0.0000e+00]])\n",
      "tensor([[1.5127e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.0799e+15, 0.0000e+00]])\n",
      "tensor([[7.6580e+16, 0.0000e+00]])\n",
      "tensor([[2.0043e+16, 0.0000e+00]])\n",
      "tensor([[7.4903e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[9.6244e+14, 0.0000e+00]])\n",
      "tensor([[4.9903e+15, 0.0000e+00]])\n",
      "tensor([[1.3468e+15, 0.0000e+00]])\n",
      "tensor([[6.1268e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.4066e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.9206e+15, 0.0000e+00]])\n",
      "tensor([[1.0780e+15, 0.0000e+00]])\n",
      "tensor([[4.4069e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.6560e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[9.1606e+14, 0.0000e+00]])\n",
      "tensor([[2.7902e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[6.0351e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.5110e+14, 0.0000e+00]])\n",
      "tensor([[7.3849e+15, 0.0000e+00]])\n",
      "tensor([[6.3108e+14, 0.0000e+00]])\n",
      "tensor([[1.2703e+17, 0.0000e+00]])\n",
      "tensor([[1.6260e+16, 0.0000e+00]])\n",
      "tensor([[1.6062e+17, 0.0000e+00]])\n",
      "tensor([[1.4181e+15, 0.0000e+00]])\n",
      "tensor([[2.6086e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.9264e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.0764e+15, 0.0000e+00]])\n",
      "tensor([[4.6550e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.2388e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.4771e+16, 0.0000e+00]])\n",
      "tensor([[2.7553e+16, 0.0000e+00]])\n",
      "tensor([[5.2270e+15, 0.0000e+00]])\n",
      "tensor([[1.9401e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.4399e+15, 0.0000e+00]])\n",
      "tensor([[7.7181e+16, 0.0000e+00]])\n",
      "tensor([[3.1494e+15, 0.0000e+00]])\n",
      "tensor([[3.2787e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.3922e+16, 0.0000e+00]])\n",
      "tensor([[3.6968e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0379e+15, 0.0000e+00]])\n",
      "tensor([[2.8080e+16, 0.0000e+00]])\n",
      "tensor([[1.5700e+15, 0.0000e+00]])\n",
      "tensor([[1.9982e+16, 0.0000e+00]])\n",
      "tensor([[1.2332e+16, 0.0000e+00]])\n",
      "tensor([[4.9252e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.7915e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.6111e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.8404e+15, 0.0000e+00]])\n",
      "tensor([[1.6283e+16, 0.0000e+00]])\n",
      "tensor([[3.8573e+16, 0.0000e+00]])\n",
      "tensor([[7.3844e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.9322e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.9992e+16, 0.0000e+00]])\n",
      "tensor([[2.7757e+16, 0.0000e+00]])\n",
      "tensor([[2.6830e+16, 0.0000e+00]])\n",
      "tensor([[1.2409e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[7.7440e+14, 0.0000e+00]])\n",
      "tensor([[5.3512e+15, 0.0000e+00]])\n",
      "tensor([[1.5471e+16, 0.0000e+00]])\n",
      "tensor([[2.5194e+16, 0.0000e+00]])\n",
      "tensor([[8.0916e+15, 0.0000e+00]])\n",
      "tensor([[3.2607e+15, 0.0000e+00]])\n",
      "tensor([[3.2834e+15, 0.0000e+00]])\n",
      "tensor([[4.3207e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[7.0515e+15, 0.0000e+00]])\n",
      "tensor([[9.8850e+14, 0.0000e+00]])\n",
      "tensor([[3.9079e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[6.0186e+16, 0.0000e+00]])\n",
      "tensor([[2.1194e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.2886e+16, 0.0000e+00]])\n",
      "tensor([[9.6081e+14, 0.0000e+00]])\n",
      "tensor([[1.5810e+15, 0.0000e+00]])\n",
      "tensor([[3.7440e+16, 0.0000e+00]])\n",
      "tensor([[4.5839e+15, 0.0000e+00]])\n",
      "tensor([[7.4701e+16, 0.0000e+00]])\n",
      "tensor([[5.4953e+16, 0.0000e+00]])\n",
      "tensor([[1.5671e+16, 0.0000e+00]])\n",
      "tensor([[5.9742e+16, 0.0000e+00]])\n",
      "tensor([[1.4617e+16, 0.0000e+00]])\n",
      "tensor([[3.0542e+15, 0.0000e+00]])\n",
      "tensor([[1.5533e+16, 0.0000e+00]])\n",
      "tensor([[4.0596e+14, 0.0000e+00]])\n",
      "tensor([[1.8445e+15, 0.0000e+00]])\n",
      "tensor([[1.8473e+16, 0.0000e+00]])\n",
      "tensor([[4.4254e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.6219e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.5773e+16, 0.0000e+00]])\n",
      "tensor([[1.3581e+17, 0.0000e+00]])\n",
      "tensor([[1.0790e+17, 0.0000e+00]])\n",
      "tensor([[6.2618e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[7.1954e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[7.2497e+15, 0.0000e+00]])\n",
      "tensor([[3.2957e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.5350e+16, 0.0000e+00]])\n",
      "tensor([[2.3003e+15, 0.0000e+00]])\n",
      "tensor([[1.9585e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[8.8336e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.6053e+16, 0.0000e+00]])\n",
      "tensor([[7.5136e+15, 0.0000e+00]])\n",
      "tensor([[5.1166e+16, 0.0000e+00]])\n",
      "tensor([[2.4995e+16, 0.0000e+00]])\n",
      "tensor([[4.2527e+15, 0.0000e+00]])\n",
      "tensor([[1.5784e+17, 0.0000e+00]])\n",
      "tensor([[1.0188e+16, 0.0000e+00]])\n",
      "tensor([[1.0511e+16, 0.0000e+00]])\n",
      "tensor([[4.4819e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.9696e+16, 0.0000e+00]])\n",
      "tensor([[1.0442e+15, 0.0000e+00]])\n",
      "tensor([[9.9232e+15, 0.0000e+00]])\n",
      "tensor([[8.0277e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.1638e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.1250e+16, 0.0000e+00]])\n",
      "tensor([[8.7911e+15, 0.0000e+00]])\n",
      "tensor([[6.4480e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.0982e+16, 0.0000e+00]])\n",
      "tensor([[1.0370e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[6.4060e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[8.9969e+15, 0.0000e+00]])\n",
      "tensor([[5.2550e+16, 0.0000e+00]])\n",
      "tensor([[4.3558e+16, 0.0000e+00]])\n",
      "tensor([[6.1767e+16, 0.0000e+00]])\n",
      "tensor([[8.1667e+16, 0.0000e+00]])\n",
      "tensor([[1.9111e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.0919e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[8.3735e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.2111e+15, 0.0000e+00]])\n",
      "tensor([[9.2568e+15, 0.0000e+00]])\n",
      "tensor([[2.4183e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[7.5437e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.5449e+17, 0.0000e+00]])\n",
      "tensor([[7.7546e+16, 0.0000e+00]])\n",
      "tensor([[7.2343e+16, 0.0000e+00]])\n",
      "tensor([[4.2501e+15, 0.0000e+00]])\n",
      "tensor([[5.1328e+15, 0.0000e+00]])\n",
      "tensor([[8.2406e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.6106e+15, 0.0000e+00]])\n",
      "tensor([[5.7172e+16, 0.0000e+00]])\n",
      "tensor([[7.4648e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.1953e+15, 0.0000e+00]])\n",
      "tensor([[7.3545e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.2352e+16, 0.0000e+00]])\n",
      "tensor([[1.0015e+15, 0.0000e+00]])\n",
      "tensor([[3.8899e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[8.4157e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.8177e+15, 0.0000e+00]])\n",
      "tensor([[1.7594e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.7160e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.7992e+15, 0.0000e+00]])\n",
      "tensor([[4.2444e+15, 0.0000e+00]])\n",
      "tensor([[3.8804e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[6.9763e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.1856e+15, 0.0000e+00]])\n",
      "tensor([[4.2845e+17, 0.0000e+00]])\n",
      "tensor([[1.0978e+15, 0.0000e+00]])\n",
      "tensor([[3.1225e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.2734e+15, 0.0000e+00]])\n",
      "tensor([[2.1516e+16, 0.0000e+00]])\n",
      "tensor([[4.5632e+14, 0.0000e+00]])\n",
      "tensor([[2.5429e+15, 0.0000e+00]])\n",
      "tensor([[1.4424e+16, 0.0000e+00]])\n",
      "tensor([[2.8971e+15, 0.0000e+00]])\n",
      "tensor([[2.1252e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.8653e+16, 0.0000e+00]])\n",
      "tensor([[1.9260e+16, 0.0000e+00]])\n",
      "tensor([[4.7293e+15, 0.0000e+00]])\n",
      "tensor([[2.4007e+15, 0.0000e+00]])\n",
      "tensor([[8.1968e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.4655e+16, 0.0000e+00]])\n",
      "tensor([[1.1238e+16, 0.0000e+00]])\n",
      "tensor([[2.0528e+16, 0.0000e+00]])\n",
      "tensor([[1.5013e+15, 0.0000e+00]])\n",
      "tensor([[2.3203e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[8.5587e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.1325e+15, 0.0000e+00]])\n",
      "tensor([[1.1919e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.5805e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[8.6731e+15, 0.0000e+00]])\n",
      "tensor([[1.2180e+16, 0.0000e+00]])\n",
      "tensor([[1.0858e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[9.5550e+14, 0.0000e+00]])\n",
      "tensor([[1.5026e+15, 0.0000e+00]])\n",
      "tensor([[2.9134e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.1965e+16, 0.0000e+00]])\n",
      "tensor([[7.7831e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[8.0624e+16, 0.0000e+00]])\n",
      "tensor([[2.1582e+16, 0.0000e+00]])\n",
      "tensor([[2.1513e+16, 0.0000e+00]])\n",
      "tensor([[2.5349e+16, 0.0000e+00]])\n",
      "tensor([[1.2282e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.2655e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.8900e+16, 0.0000e+00]])\n",
      "tensor([[1.8425e+16, 0.0000e+00]])\n",
      "tensor([[8.9707e+16, 0.0000e+00]])\n",
      "tensor([[3.3676e+15, 0.0000e+00]])\n",
      "tensor([[1.9828e+14, 0.0000e+00]])\n",
      "tensor([[4.2124e+15, 0.0000e+00]])\n",
      "tensor([[2.0112e+16, 0.0000e+00]])\n",
      "tensor([[1.4206e+17, 0.0000e+00]])\n",
      "tensor([[1.3817e+16, 0.0000e+00]])\n",
      "tensor([[4.9629e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.5215e+15, 0.0000e+00]])\n",
      "tensor([[5.5747e+15, 0.0000e+00]])\n",
      "tensor([[3.0123e+16, 0.0000e+00]])\n",
      "tensor([[1.5577e+14, 0.0000e+00]])\n",
      "tensor([[4.9435e+15, 0.0000e+00]])\n",
      "tensor([[3.7560e+15, 0.0000e+00]])\n",
      "tensor([[6.7842e+16, 0.0000e+00]])\n",
      "tensor([[1.0587e+15, 0.0000e+00]])\n",
      "tensor([[3.5366e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.3589e+16, 0.0000e+00]])\n",
      "tensor([[2.3159e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.7306e+16, 0.0000e+00]])\n",
      "tensor([[7.1426e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.6576e+16, 0.0000e+00]])\n",
      "tensor([[5.2442e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.2168e+16, 0.0000e+00]])\n",
      "tensor([[6.4715e+13, 0.0000e+00]])\n",
      "tensor([[4.9397e+16, 0.0000e+00]])\n",
      "tensor([[9.0222e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.5506e+16, 0.0000e+00]])\n",
      "tensor([[1.7577e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.8876e+15, 0.0000e+00]])\n",
      "tensor([[3.3241e+17, 0.0000e+00]])\n",
      "tensor([[2.8895e+16, 0.0000e+00]])\n",
      "tensor([[1.2958e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.9401e+15, 0.0000e+00]])\n",
      "tensor([[1.3663e+15, 0.0000e+00]])\n",
      "tensor([[9.8906e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.3011e+15, 0.0000e+00]])\n",
      "tensor([[1.2983e+16, 0.0000e+00]])\n",
      "tensor([[3.9415e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.3744e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.1058e+15, 0.0000e+00]])\n",
      "tensor([[4.3156e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.1459e+16, 0.0000e+00]])\n",
      "tensor([[1.0855e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.2725e+16, 0.0000e+00]])\n",
      "tensor([[2.0967e+15, 0.0000e+00]])\n",
      "tensor([[3.6988e+14, 0.0000e+00]])\n",
      "tensor([[2.4810e+15, 0.0000e+00]])\n",
      "tensor([[1.6560e+15, 0.0000e+00]])\n",
      "tensor([[9.9290e+15, 0.0000e+00]])\n",
      "tensor([[4.7410e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.9567e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.5779e+16, 0.0000e+00]])\n",
      "tensor([[1.0952e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.9810e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.6114e+16, 0.0000e+00]])\n",
      "tensor([[1.3921e+16, 0.0000e+00]])\n",
      "tensor([[3.1050e+16, 0.0000e+00]])\n",
      "tensor([[2.3943e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.3468e+16, 0.0000e+00]])\n",
      "tensor([[5.3254e+15, 0.0000e+00]])\n",
      "tensor([[6.2657e+15, 0.0000e+00]])\n",
      "tensor([[2.4252e+16, 0.0000e+00]])\n",
      "tensor([[1.6707e+16, 0.0000e+00]])\n",
      "tensor([[4.5088e+16, 0.0000e+00]])\n",
      "tensor([[9.6736e+15, 0.0000e+00]])\n",
      "tensor([[1.3597e+17, 0.0000e+00]])\n",
      "tensor([[3.7825e+16, 0.0000e+00]])\n",
      "tensor([[1.3931e+15, 0.0000e+00]])\n",
      "tensor([[3.2993e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.0086e+16, 0.0000e+00]])\n",
      "tensor([[1.2955e+14, 0.0000e+00]])\n",
      "tensor([[1.5727e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.1897e+15, 0.0000e+00]])\n",
      "tensor([[7.0179e+14, 0.0000e+00]])\n",
      "tensor([[1.6379e+15, 0.0000e+00]])\n",
      "tensor([[3.1220e+16, 0.0000e+00]])\n",
      "tensor([[3.7819e+15, 0.0000e+00]])\n",
      "tensor([[1.9207e+15, 0.0000e+00]])\n",
      "tensor([[4.8075e+16, 0.0000e+00]])\n",
      "tensor([[1.6140e+16, 0.0000e+00]])\n",
      "tensor([[1.8929e+16, 0.0000e+00]])\n",
      "tensor([[9.8559e+16, 0.0000e+00]])\n",
      "tensor([[2.6341e+15, 0.0000e+00]])\n",
      "tensor([[1.9104e+15, 0.0000e+00]])\n",
      "tensor([[1.2952e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.9490e+16, 0.0000e+00]])\n",
      "tensor([[3.2217e+16, 0.0000e+00]])\n",
      "tensor([[2.7455e+17, 0.0000e+00]])\n",
      "tensor([[3.0744e+16, 0.0000e+00]])\n",
      "tensor([[3.0550e+16, 0.0000e+00]])\n",
      "tensor([[2.5339e+14, 0.0000e+00]])\n",
      "tensor([[4.2473e+15, 0.0000e+00]])\n",
      "tensor([[3.1682e+15, 0.0000e+00]])\n",
      "tensor([[3.0416e+16, 0.0000e+00]])\n",
      "tensor([[2.8659e+15, 0.0000e+00]])\n",
      "tensor([[1.2133e+16, 0.0000e+00]])\n",
      "tensor([[1.6741e+16, 0.0000e+00]])\n",
      "tensor([[1.6131e+15, 0.0000e+00]])\n",
      "tensor([[8.0994e+16, 0.0000e+00]])\n",
      "tensor([[1.0121e+16, 0.0000e+00]])\n",
      "tensor([[3.0267e+16, 0.0000e+00]])\n",
      "tensor([[2.8908e+16, 0.0000e+00]])\n",
      "tensor([[3.8099e+15, 0.0000e+00]])\n",
      "tensor([[4.5718e+16, 0.0000e+00]])\n",
      "tensor([[9.2747e+15, 0.0000e+00]])\n",
      "tensor([[3.0419e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[6.0711e+15, 0.0000e+00]])\n",
      "tensor([[6.1814e+15, 0.0000e+00]])\n",
      "tensor([[4.9065e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.4978e+16, 0.0000e+00]])\n",
      "tensor([[8.4807e+16, 0.0000e+00]])\n",
      "tensor([[2.0785e+16, 0.0000e+00]])\n",
      "tensor([[4.6046e+16, 0.0000e+00]])\n",
      "tensor([[2.5753e+16, 0.0000e+00]])\n",
      "tensor([[6.2821e+14, 0.0000e+00]])\n",
      "tensor([[4.9451e+15, 0.0000e+00]])\n",
      "tensor([[1.6124e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.0415e+15, 0.0000e+00]])\n",
      "tensor([[5.3416e+14, 0.0000e+00]])\n",
      "tensor([[2.8792e+15, 0.0000e+00]])\n",
      "tensor([[2.9755e+17, 0.0000e+00]])\n",
      "tensor([[6.6344e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[7.6769e+16, 0.0000e+00]])\n",
      "tensor([[7.1294e+15, 0.0000e+00]])\n",
      "tensor([[1.8455e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.1630e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.8592e+15, 0.0000e+00]])\n",
      "tensor([[1.4584e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.9340e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.1940e+14, 0.0000e+00]])\n",
      "tensor([[6.4746e+14, 0.0000e+00]])\n",
      "tensor([[2.6060e+15, 0.0000e+00]])\n",
      "tensor([[5.9152e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.0932e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.3672e+15, 0.0000e+00]])\n",
      "tensor([[1.7469e+16, 0.0000e+00]])\n",
      "tensor([[7.0278e+16, 0.0000e+00]])\n",
      "tensor([[3.3245e+15, 0.0000e+00]])\n",
      "tensor([[2.6985e+15, 0.0000e+00]])\n",
      "tensor([[4.7851e+16, 0.0000e+00]])\n",
      "tensor([[8.0467e+15, 0.0000e+00]])\n",
      "tensor([[1.2803e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.0147e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.9951e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.9537e+16, 0.0000e+00]])\n",
      "tensor([[1.4804e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.4580e+15, 0.0000e+00]])\n",
      "tensor([[7.7303e+15, 0.0000e+00]])\n",
      "tensor([[2.7996e+15, 0.0000e+00]])\n",
      "tensor([[3.6908e+15, 0.0000e+00]])\n",
      "tensor([[2.4270e+15, 0.0000e+00]])\n",
      "tensor([[5.2690e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.3292e+15, 0.0000e+00]])\n",
      "tensor([[3.3500e+15, 0.0000e+00]])\n",
      "tensor([[2.1957e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.0991e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.3624e+14, 0.0000e+00]])\n",
      "tensor([[2.8289e+16, 0.0000e+00]])\n",
      "tensor([[2.0646e+16, 0.0000e+00]])\n",
      "tensor([[3.4803e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.5439e+15, 0.0000e+00]])\n",
      "tensor([[6.6038e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.2083e+16, 0.0000e+00]])\n",
      "tensor([[9.9214e+15, 0.0000e+00]])\n",
      "tensor([[6.7904e+15, 0.0000e+00]])\n",
      "tensor([[6.0904e+15, 0.0000e+00]])\n",
      "tensor([[7.8087e+15, 0.0000e+00]])\n",
      "tensor([[2.3310e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.8264e+15, 0.0000e+00]])\n",
      "tensor([[4.7102e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[8.8559e+15, 0.0000e+00]])\n",
      "tensor([[3.0827e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.0069e+15, 0.0000e+00]])\n",
      "tensor([[5.6121e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[6.3655e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.4536e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.4369e+16, 0.0000e+00]])\n",
      "tensor([[4.6330e+15, 0.0000e+00]])\n",
      "tensor([[1.1640e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.8940e+16, 0.0000e+00]])\n",
      "tensor([[1.8673e+16, 0.0000e+00]])\n",
      "tensor([[1.7791e+16, 0.0000e+00]])\n",
      "tensor([[1.0833e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[8.8054e+15, 0.0000e+00]])\n",
      "tensor([[3.7067e+16, 0.0000e+00]])\n",
      "tensor([[1.9000e+16, 0.0000e+00]])\n",
      "tensor([[6.1406e+15, 0.0000e+00]])\n",
      "tensor([[3.4108e+15, 0.0000e+00]])\n",
      "tensor([[1.3048e+17, 0.0000e+00]])\n",
      "tensor([[2.4176e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.8942e+16, 0.0000e+00]])\n",
      "tensor([[4.0085e+16, 0.0000e+00]])\n",
      "tensor([[1.4041e+15, 0.0000e+00]])\n",
      "tensor([[6.9369e+15, 0.0000e+00]])\n",
      "tensor([[2.4667e+16, 0.0000e+00]])\n",
      "tensor([[6.4612e+15, 0.0000e+00]])\n",
      "tensor([[6.2088e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.8227e+16, 0.0000e+00]])\n",
      "tensor([[1.2145e+15, 0.0000e+00]])\n",
      "tensor([[9.1723e+15, 0.0000e+00]])\n",
      "tensor([[4.2194e+16, 0.0000e+00]])\n",
      "tensor([[7.5891e+13, 0.0000e+00]])\n",
      "tensor([[3.5846e+16, 0.0000e+00]])\n",
      "tensor([[2.8726e+15, 0.0000e+00]])\n",
      "tensor([[5.4023e+14, 0.0000e+00]])\n",
      "tensor([[6.7179e+16, 0.0000e+00]])\n",
      "tensor([[4.8480e+15, 0.0000e+00]])\n",
      "tensor([[1.4571e+17, 0.0000e+00]])\n",
      "tensor([[3.8449e+16, 0.0000e+00]])\n",
      "tensor([[8.4539e+15, 0.0000e+00]])\n",
      "tensor([[1.1590e+16, 0.0000e+00]])\n",
      "tensor([[4.8874e+15, 0.0000e+00]])\n",
      "tensor([[5.1161e+15, 0.0000e+00]])\n",
      "tensor([[9.5843e+15, 0.0000e+00]])\n",
      "tensor([[3.1008e+15, 0.0000e+00]])\n",
      "tensor([[3.0889e+15, 0.0000e+00]])\n",
      "tensor([[9.3029e+15, 0.0000e+00]])\n",
      "tensor([[2.0391e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.9613e+15, 0.0000e+00]])\n",
      "tensor([[1.4095e+16, 0.0000e+00]])\n",
      "tensor([[9.9439e+15, 0.0000e+00]])\n",
      "tensor([[4.8262e+15, 0.0000e+00]])\n",
      "tensor([[1.1824e+16, 0.0000e+00]])\n",
      "tensor([[1.5991e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.4959e+16, 0.0000e+00]])\n",
      "tensor([[8.4040e+14, 0.0000e+00]])\n",
      "tensor([[3.7468e+16, 0.0000e+00]])\n",
      "tensor([[1.8163e+15, 0.0000e+00]])\n",
      "tensor([[3.6021e+15, 0.0000e+00]])\n",
      "tensor([[1.5793e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[7.7634e+15, 0.0000e+00]])\n",
      "tensor([[2.7317e+15, 0.0000e+00]])\n",
      "tensor([[6.2592e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.9540e+16, 0.0000e+00]])\n",
      "tensor([[4.7849e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.6529e+16, 0.0000e+00]])\n",
      "tensor([[4.4683e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.5172e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.7693e+16, 0.0000e+00]])\n",
      "tensor([[3.5357e+15, 0.0000e+00]])\n",
      "tensor([[1.7108e+16, 0.0000e+00]])\n",
      "tensor([[5.5238e+13, 0.0000e+00]])\n",
      "tensor([[2.3267e+14, 0.0000e+00]])\n",
      "tensor([[4.6167e+15, 0.0000e+00]])\n",
      "tensor([[2.2504e+16, 0.0000e+00]])\n",
      "tensor([[5.4058e+15, 0.0000e+00]])\n",
      "tensor([[1.4674e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.2206e+16, 0.0000e+00]])\n",
      "tensor([[2.2674e+16, 0.0000e+00]])\n",
      "tensor([[8.4706e+16, 0.0000e+00]])\n",
      "tensor([[4.2537e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.3719e+16, 0.0000e+00]])\n",
      "tensor([[3.5331e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.3003e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.1126e+16, 0.0000e+00]])\n",
      "tensor([[2.3684e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.1740e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.8386e+15, 0.0000e+00]])\n",
      "tensor([[2.6479e+16, 0.0000e+00]])\n",
      "tensor([[1.6407e+16, 0.0000e+00]])\n",
      "tensor([[2.6559e+15, 0.0000e+00]])\n",
      "tensor([[3.8040e+16, 0.0000e+00]])\n",
      "tensor([[2.1098e+15, 0.0000e+00]])\n",
      "tensor([[3.5179e+17, 0.0000e+00]])\n",
      "tensor([[4.8527e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.0785e+16, 0.0000e+00]])\n",
      "tensor([[1.5844e+14, 0.0000e+00]])\n",
      "tensor([[8.0588e+15, 0.0000e+00]])\n",
      "tensor([[8.4256e+15, 0.0000e+00]])\n",
      "tensor([[5.7851e+15, 0.0000e+00]])\n",
      "tensor([[8.2453e+15, 0.0000e+00]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.9754e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.8245e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[7.5943e+15, 0.0000e+00]])\n",
      "tensor([[5.7337e+15, 0.0000e+00]])\n",
      "tensor([[2.4138e+16, 0.0000e+00]])\n",
      "tensor([[1.7463e+15, 0.0000e+00]])\n",
      "tensor([[5.7589e+16, 0.0000e+00]])\n",
      "tensor([[5.7880e+15, 0.0000e+00]])\n",
      "tensor([[4.9294e+16, 0.0000e+00]])\n",
      "tensor([[1.0363e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[9.6956e+14, 0.0000e+00]])\n",
      "tensor([[7.8485e+15, 0.0000e+00]])\n",
      "tensor([[4.2387e+15, 0.0000e+00]])\n",
      "tensor([[1.5361e+15, 0.0000e+00]])\n",
      "tensor([[8.7675e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.1512e+15, 0.0000e+00]])\n",
      "tensor([[2.2889e+15, 0.0000e+00]])\n",
      "tensor([[3.8673e+15, 0.0000e+00]])\n",
      "tensor([[4.7156e+14, 0.0000e+00]])\n",
      "tensor([[6.9075e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.8231e+14, 0.0000e+00]])\n",
      "tensor([[4.9765e+14, 0.0000e+00]])\n",
      "tensor([[2.9567e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.6851e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.7471e+15, 0.0000e+00]])\n",
      "tensor([[5.5979e+15, 0.0000e+00]])\n",
      "tensor([[1.0389e+17, 0.0000e+00]])\n",
      "tensor([[3.7380e+15, 0.0000e+00]])\n",
      "tensor([[6.9737e+15, 0.0000e+00]])\n",
      "tensor([[3.9910e+15, 0.0000e+00]])\n",
      "tensor([[1.9749e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.0507e+16, 0.0000e+00]])\n",
      "tensor([[7.2195e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.3484e+15, 0.0000e+00]])\n",
      "tensor([[6.3036e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.6450e+16, 0.0000e+00]])\n",
      "tensor([[4.9274e+16, 0.0000e+00]])\n",
      "tensor([[4.3380e+15, 0.0000e+00]])\n",
      "tensor([[9.0001e+15, 0.0000e+00]])\n",
      "tensor([[3.1197e+16, 0.0000e+00]])\n",
      "tensor([[1.0471e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[7.0516e+15, 0.0000e+00]])\n",
      "tensor([[3.7008e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.6083e+16, 0.0000e+00]])\n",
      "tensor([[7.6935e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.7719e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[7.2010e+15, 0.0000e+00]])\n",
      "tensor([[1.1500e+16, 0.0000e+00]])\n",
      "tensor([[8.4395e+13, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.3542e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.4248e+15, 0.0000e+00]])\n",
      "tensor([[2.6461e+15, 0.0000e+00]])\n",
      "tensor([[2.4370e+17, 0.0000e+00]])\n",
      "tensor([[2.6017e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.1223e+16, 0.0000e+00]])\n",
      "tensor([[5.8842e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.5992e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[6.4571e+16, 0.0000e+00]])\n",
      "tensor([[3.6246e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.1471e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.9557e+16, 0.0000e+00]])\n",
      "tensor([[2.8947e+15, 0.0000e+00]])\n",
      "tensor([[2.5038e+16, 0.0000e+00]])\n",
      "tensor([[1.0067e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.2400e+15, 0.0000e+00]])\n",
      "tensor([[1.1405e+17, 0.0000e+00]])\n",
      "tensor([[1.8214e+16, 0.0000e+00]])\n",
      "tensor([[7.1939e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.7726e+15, 0.0000e+00]])\n",
      "tensor([[7.0149e+15, 0.0000e+00]])\n",
      "tensor([[1.1203e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[7.2960e+16, 0.0000e+00]])\n",
      "tensor([[1.8747e+16, 0.0000e+00]])\n",
      "tensor([[5.1237e+16, 0.0000e+00]])\n",
      "tensor([[5.1592e+16, 0.0000e+00]])\n",
      "tensor([[5.5867e+16, 0.0000e+00]])\n",
      "tensor([[3.4962e+15, 0.0000e+00]])\n",
      "tensor([[4.7025e+15, 0.0000e+00]])\n",
      "tensor([[1.7067e+17, 0.0000e+00]])\n",
      "tensor([[8.8324e+14, 0.0000e+00]])\n",
      "tensor([[7.9340e+14, 0.0000e+00]])\n",
      "tensor([[4.0167e+15, 0.0000e+00]])\n",
      "tensor([[3.6383e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.1305e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[7.6302e+15, 0.0000e+00]])\n",
      "tensor([[3.4924e+16, 0.0000e+00]])\n",
      "tensor([[2.0080e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.4603e+16, 0.0000e+00]])\n",
      "tensor([[2.7457e+16, 0.0000e+00]])\n",
      "tensor([[3.1436e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[9.7524e+16, 0.0000e+00]])\n",
      "tensor([[7.9693e+16, 0.0000e+00]])\n",
      "tensor([[5.2754e+14, 0.0000e+00]])\n",
      "tensor([[4.9169e+15, 0.0000e+00]])\n",
      "tensor([[2.6960e+16, 0.0000e+00]])\n",
      "tensor([[8.4897e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.2276e+16, 0.0000e+00]])\n",
      "tensor([[8.2760e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.7081e+16, 0.0000e+00]])\n",
      "tensor([[8.0881e+15, 0.0000e+00]])\n",
      "tensor([[4.8101e+16, 0.0000e+00]])\n",
      "tensor([[2.3269e+16, 0.0000e+00]])\n",
      "tensor([[5.4847e+14, 0.0000e+00]])\n",
      "tensor([[1.6387e+15, 0.0000e+00]])\n",
      "tensor([[7.4098e+16, 0.0000e+00]])\n",
      "tensor([[8.4294e+14, 0.0000e+00]])\n",
      "tensor([[1.3831e+15, 0.0000e+00]])\n",
      "tensor([[6.2176e+16, 0.0000e+00]])\n",
      "tensor([[3.2847e+14, 0.0000e+00]])\n",
      "tensor([[4.2781e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.1603e+16, 0.0000e+00]])\n",
      "tensor([[7.5427e+13, 0.0000e+00]])\n",
      "tensor([[1.1670e+16, 0.0000e+00]])\n",
      "tensor([[1.6959e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.6910e+16, 0.0000e+00]])\n",
      "tensor([[1.2981e+16, 0.0000e+00]])\n",
      "tensor([[2.1277e+16, 0.0000e+00]])\n",
      "tensor([[2.4175e+16, 0.0000e+00]])\n",
      "tensor([[1.6068e+17, 0.0000e+00]])\n",
      "tensor([[2.9238e+15, 0.0000e+00]])\n",
      "tensor([[1.2654e+15, 0.0000e+00]])\n",
      "tensor([[7.3087e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[7.8518e+16, 0.0000e+00]])\n",
      "tensor([[1.2145e+15, 0.0000e+00]])\n",
      "tensor([[1.8634e+15, 0.0000e+00]])\n",
      "tensor([[3.3478e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[8.7817e+15, 0.0000e+00]])\n",
      "tensor([[6.8295e+15, 0.0000e+00]])\n",
      "tensor([[3.8450e+15, 0.0000e+00]])\n",
      "tensor([[1.7434e+16, 0.0000e+00]])\n",
      "tensor([[5.1206e+14, 0.0000e+00]])\n",
      "tensor([[9.8342e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.4729e+15, 0.0000e+00]])\n",
      "tensor([[2.5512e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.7312e+15, 0.0000e+00]])\n",
      "tensor([[4.3290e+16, 0.0000e+00]])\n",
      "tensor([[4.8406e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.3677e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.3844e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.3326e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.9735e+14, 0.0000e+00]])\n",
      "tensor([[1.6547e+17, 0.0000e+00]])\n",
      "tensor([[1.6832e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.5689e+16, 0.0000e+00]])\n",
      "tensor([[6.2725e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.1058e+16, 0.0000e+00]])\n",
      "tensor([[1.9208e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.6737e+15, 0.0000e+00]])\n",
      "tensor([[1.3663e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.2252e+15, 0.0000e+00]])\n",
      "tensor([[3.0138e+16, 0.0000e+00]])\n",
      "tensor([[8.8365e+15, 0.0000e+00]])\n",
      "tensor([[1.0474e+16, 0.0000e+00]])\n",
      "tensor([[1.6654e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.5015e+16, 0.0000e+00]])\n",
      "tensor([[1.8850e+15, 0.0000e+00]])\n",
      "tensor([[8.3294e+14, 0.0000e+00]])\n",
      "tensor([[1.4953e+17, 0.0000e+00]])\n",
      "tensor([[6.1150e+15, 0.0000e+00]])\n",
      "tensor([[1.0796e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.7419e+15, 0.0000e+00]])\n",
      "tensor([[1.7353e+15, 0.0000e+00]])\n",
      "tensor([[4.2356e+16, 0.0000e+00]])\n",
      "tensor([[3.5502e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.3151e+14, 0.0000e+00]])\n",
      "tensor([[1.4385e+16, 0.0000e+00]])\n",
      "tensor([[8.9297e+16, 0.0000e+00]])\n",
      "tensor([[1.8809e+15, 0.0000e+00]])\n",
      "tensor([[2.6303e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[7.4358e+15, 0.0000e+00]])\n",
      "tensor([[8.7976e+15, 0.0000e+00]])\n",
      "tensor([[2.8171e+16, 0.0000e+00]])\n",
      "tensor([[8.5405e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.8423e+15, 0.0000e+00]])\n",
      "tensor([[1.1062e+16, 0.0000e+00]])\n",
      "tensor([[1.2645e+15, 0.0000e+00]])\n",
      "tensor([[7.8826e+15, 0.0000e+00]])\n",
      "tensor([[2.3847e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.4511e+17, 0.0000e+00]])\n",
      "tensor([[2.2961e+15, 0.0000e+00]])\n",
      "tensor([[2.0670e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.9318e+16, 0.0000e+00]])\n",
      "tensor([[2.0264e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.0139e+17, 0.0000e+00]])\n",
      "tensor([[3.5138e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.6498e+16, 0.0000e+00]])\n",
      "tensor([[3.8373e+16, 0.0000e+00]])\n",
      "tensor([[1.1249e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.1644e+16, 0.0000e+00]])\n",
      "tensor([[1.7540e+16, 0.0000e+00]])\n",
      "tensor([[5.4244e+16, 0.0000e+00]])\n",
      "tensor([[5.4413e+15, 0.0000e+00]])\n",
      "tensor([[5.6055e+15, 0.0000e+00]])\n",
      "tensor([[3.6390e+16, 0.0000e+00]])\n",
      "tensor([[3.1125e+17, 0.0000e+00]])\n",
      "tensor([[5.1980e+15, 0.0000e+00]])\n",
      "tensor([[4.3961e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.4298e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.1537e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.9187e+15, 0.0000e+00]])\n",
      "tensor([[1.1613e+16, 0.0000e+00]])\n",
      "tensor([[8.6614e+14, 0.0000e+00]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.8412e+16, 0.0000e+00]])\n",
      "tensor([[6.7889e+14, 0.0000e+00]])\n",
      "tensor([[1.0083e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.0242e+16, 0.0000e+00]])\n",
      "tensor([[5.6486e+15, 0.0000e+00]])\n",
      "tensor([[2.0287e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.8378e+16, 0.0000e+00]])\n",
      "tensor([[3.9437e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[7.6638e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.0113e+15, 0.0000e+00]])\n",
      "tensor([[3.4909e+15, 0.0000e+00]])\n",
      "tensor([[2.7518e+16, 0.0000e+00]])\n",
      "tensor([[1.1754e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[9.7704e+15, 0.0000e+00]])\n",
      "tensor([[4.6615e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.6548e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[8.7204e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.2306e+16, 0.0000e+00]])\n",
      "tensor([[3.3786e+15, 0.0000e+00]])\n",
      "tensor([[7.2383e+15, 0.0000e+00]])\n",
      "tensor([[2.4674e+16, 0.0000e+00]])\n",
      "tensor([[2.0568e+15, 0.0000e+00]])\n",
      "tensor([[2.9926e+15, 0.0000e+00]])\n",
      "tensor([[7.7170e+16, 0.0000e+00]])\n",
      "tensor([[3.1430e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.1601e+16, 0.0000e+00]])\n",
      "tensor([[7.0058e+14, 0.0000e+00]])\n",
      "tensor([[1.0436e+16, 0.0000e+00]])\n",
      "tensor([[1.3529e+16, 0.0000e+00]])\n",
      "tensor([[1.4082e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.8937e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.7124e+17, 0.0000e+00]])\n",
      "tensor([[4.0689e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.2778e+15, 0.0000e+00]])\n",
      "tensor([[3.8361e+16, 0.0000e+00]])\n",
      "tensor([[8.4362e+13, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.9081e+15, 0.0000e+00]])\n",
      "tensor([[5.2584e+15, 0.0000e+00]])\n",
      "tensor([[3.9995e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[5.0356e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.6115e+15, 0.0000e+00]])\n",
      "tensor([[2.1831e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[6.9775e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.6563e+15, 0.0000e+00]])\n",
      "tensor([[2.9173e+16, 0.0000e+00]])\n",
      "tensor([[2.4902e+16, 0.0000e+00]])\n",
      "tensor([[5.0897e+14, 0.0000e+00]])\n",
      "tensor([[3.7028e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.8709e+14, 0.0000e+00]])\n",
      "tensor([[8.1377e+14, 0.0000e+00]])\n",
      "tensor([[3.8470e+16, 0.0000e+00]])\n",
      "tensor([[6.2469e+16, 0.0000e+00]])\n",
      "tensor([[2.3442e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.7402e+16, 0.0000e+00]])\n",
      "tensor([[4.8499e+16, 0.0000e+00]])\n",
      "tensor([[9.8107e+15, 0.0000e+00]])\n",
      "tensor([[2.6180e+16, 0.0000e+00]])\n",
      "tensor([[3.2863e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.8097e+16, 0.0000e+00]])\n",
      "tensor([[9.3172e+16, 0.0000e+00]])\n",
      "tensor([[1.2796e+15, 0.0000e+00]])\n",
      "tensor([[2.4765e+16, 0.0000e+00]])\n",
      "tensor([[1.6756e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.3590e+16, 0.0000e+00]])\n",
      "tensor([[1.8017e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[7.4627e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.1358e+17, 0.0000e+00]])\n",
      "tensor([[1.5484e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.7567e+16, 0.0000e+00]])\n",
      "tensor([[3.7108e+15, 0.0000e+00]])\n",
      "tensor([[2.5833e+16, 0.0000e+00]])\n",
      "tensor([[6.3806e+15, 0.0000e+00]])\n",
      "tensor([[4.4544e+16, 0.0000e+00]])\n",
      "tensor([[6.4082e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[7.8493e+15, 0.0000e+00]])\n",
      "tensor([[7.2835e+14, 0.0000e+00]])\n",
      "tensor([[9.0069e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.9710e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.9328e+15, 0.0000e+00]])\n",
      "tensor([[1.4895e+16, 0.0000e+00]])\n",
      "tensor([[2.9168e+16, 0.0000e+00]])\n",
      "tensor([[1.5013e+17, 0.0000e+00]])\n",
      "tensor([[1.9712e+16, 0.0000e+00]])\n",
      "tensor([[2.0981e+16, 0.0000e+00]])\n",
      "tensor([[2.0133e+16, 0.0000e+00]])\n",
      "tensor([[2.1485e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.7939e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.7725e+15, 0.0000e+00]])\n",
      "tensor([[1.5395e+15, 0.0000e+00]])\n",
      "tensor([[3.8714e+14, 0.0000e+00]])\n",
      "tensor([[1.2078e+14, 0.0000e+00]])\n",
      "tensor([[8.8937e+14, 0.0000e+00]])\n",
      "tensor([[4.2667e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[8.7044e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.6780e+14, 0.0000e+00]])\n",
      "tensor([[2.6293e+16, 0.0000e+00]])\n",
      "tensor([[9.8783e+15, 0.0000e+00]])\n",
      "tensor([[2.7445e+15, 0.0000e+00]])\n",
      "tensor([[1.1886e+15, 0.0000e+00]])\n",
      "tensor([[2.8696e+15, 0.0000e+00]])\n",
      "tensor([[9.3931e+16, 0.0000e+00]])\n",
      "tensor([[5.9600e+14, 0.0000e+00]])\n",
      "tensor([[1.8107e+17, 0.0000e+00]])\n",
      "tensor([[7.3247e+15, 0.0000e+00]])\n",
      "tensor([[8.3886e+16, 0.0000e+00]])\n",
      "tensor([[1.4787e+17, 0.0000e+00]])\n",
      "tensor([[5.1016e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.2837e+16, 0.0000e+00]])\n",
      "tensor([[2.2968e+16, 0.0000e+00]])\n",
      "tensor([[1.7946e+14, 0.0000e+00]])\n",
      "tensor([[1.0088e+15, 0.0000e+00]])\n",
      "tensor([[3.2529e+16, 0.0000e+00]])\n",
      "tensor([[4.6317e+15, 0.0000e+00]])\n",
      "tensor([[2.9942e+16, 0.0000e+00]])\n",
      "tensor([[3.8724e+16, 0.0000e+00]])\n",
      "tensor([[7.1128e+14, 0.0000e+00]])\n",
      "tensor([[4.1574e+15, 0.0000e+00]])\n",
      "tensor([[6.8168e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[9.1488e+16, 0.0000e+00]])\n",
      "tensor([[4.0468e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.8174e+16, 0.0000e+00]])\n",
      "tensor([[2.7169e+15, 0.0000e+00]])\n",
      "tensor([[1.6576e+16, 0.0000e+00]])\n",
      "tensor([[3.1615e+15, 0.0000e+00]])\n",
      "tensor([[8.8198e+15, 0.0000e+00]])\n",
      "tensor([[1.9205e+16, 0.0000e+00]])\n",
      "tensor([[3.9972e+15, 0.0000e+00]])\n",
      "tensor([[2.7352e+17, 0.0000e+00]])\n",
      "tensor([[2.2392e+14, 0.0000e+00]])\n",
      "tensor([[8.8931e+15, 0.0000e+00]])\n",
      "tensor([[1.0954e+16, 0.0000e+00]])\n",
      "tensor([[1.1344e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.4887e+16, 0.0000e+00]])\n",
      "tensor([[1.6683e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.7825e+15, 0.0000e+00]])\n",
      "tensor([[3.5547e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.1985e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.5238e+15, 0.0000e+00]])\n",
      "tensor([[6.6506e+16, 0.0000e+00]])\n",
      "tensor([[8.7775e+15, 0.0000e+00]])\n",
      "tensor([[3.0847e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.9060e+15, 0.0000e+00]])\n",
      "tensor([[2.2314e+16, 0.0000e+00]])\n",
      "tensor([[3.4655e+16, 0.0000e+00]])\n",
      "tensor([[4.3951e+16, 0.0000e+00]])\n",
      "tensor([[5.6874e+15, 0.0000e+00]])\n",
      "tensor([[6.9510e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.1664e+16, 0.0000e+00]])\n",
      "tensor([[1.0226e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[3.4463e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.5270e+16, 0.0000e+00]])\n",
      "tensor([[2.4168e+16, 0.0000e+00]])\n",
      "tensor([[2.5493e+16, 0.0000e+00]])\n",
      "tensor([[1.3441e+17, 0.0000e+00]])\n",
      "tensor([[6.6400e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.6719e+16, 0.0000e+00]])\n",
      "tensor([[9.9223e+15, 0.0000e+00]])\n",
      "tensor([[2.0670e+17, 0.0000e+00]])\n",
      "tensor([[2.4404e+15, 0.0000e+00]])\n",
      "tensor([[2.3334e+17, 0.0000e+00]])\n",
      "tensor([[6.5505e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.4386e+17, 0.0000e+00]])\n",
      "tensor([[2.9297e+15, 0.0000e+00]])\n",
      "tensor([[1.2925e+15, 0.0000e+00]])\n",
      "tensor([[6.7496e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.6056e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[6.8472e+14, 0.0000e+00]])\n",
      "tensor([[1.2707e+16, 0.0000e+00]])\n",
      "tensor([[5.0167e+15, 0.0000e+00]])\n",
      "tensor([[4.6557e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.6747e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.5460e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[9.2110e+13, 0.0000e+00]])\n",
      "tensor([[1.8030e+14, 0.0000e+00]])\n",
      "tensor([[2.3692e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.2638e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.7098e+14, 0.0000e+00]])\n",
      "tensor([[2.7552e+15, 0.0000e+00]])\n",
      "tensor([[2.8148e+15, 0.0000e+00]])\n",
      "tensor([[2.5958e+16, 0.0000e+00]])\n",
      "tensor([[5.9625e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.0717e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.0646e+16, 0.0000e+00]])\n",
      "tensor([[1.0213e+16, 0.0000e+00]])\n",
      "tensor([[2.2583e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[2.1994e+16, 0.0000e+00]])\n",
      "tensor([[2.9114e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[6.2119e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[4.3744e+14, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[8.2257e+16, 0.0000e+00]])\n",
      "tensor([[1.1791e+17, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[1.4477e+16, 0.0000e+00]])\n",
      "tensor([[1.7019e+16, 0.0000e+00]])\n",
      "tensor([[1.4254e+16, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[6.5255e+15, 0.0000e+00]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.7156e+15, 0.0000e+00]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[8.2887e+14, 0.0000e+00]])\n",
      "tensor([[1.7780e+17, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for row in df_dev.values:\n",
    "        txt = row[1] #row['Text']\n",
    "        pronoun = row[2] #row['Pronoun']\n",
    "        ca = row[4] #row['A']\n",
    "        cb = row[7]#row['B']\n",
    "        label = pd.DataFrame()\n",
    "        label['A'] = row[6] #row['A-coref']\n",
    "        label['B'] = row[9] #row['B-coref']\n",
    "        \n",
    "        bow_vec = simple_tokenizer(txt, pronoun, ca, cb)\n",
    "        log_probs = anmodel(bow_vec)\n",
    "        print(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tensor([[-1.8322,  0.5050, -0.4250,  0.7594, -0.8195],\n",
      "        [-0.6360,  0.5347, -2.3115, -0.4379, -0.1315],\n",
      "        [ 0.4859, -0.5824,  1.6323, -1.7086, -0.4659]], requires_grad=True)\n",
      "target tensor([2, 0, 4])\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "print('input', input)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "print('target', target)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1000, 0.2000, 0.4000, 0.8000]])\n",
      "tensor([[ 3,  0, -1,  1]])\n",
      "tensor(0.8500)\n"
     ]
    }
   ],
   "source": [
    "loss = nn.MultiLabelMarginLoss()\n",
    "x = torch.FloatTensor([[0.1, 0.2, 0.4, 0.8]])\n",
    "print(x)\n",
    "# for target y, only consider labels 3 and 0, not after label -1\n",
    "y = torch.LongTensor([[3, 0, -1, 1]])\n",
    "print(y)\n",
    "print(loss(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_ix['True']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokens: 999994\n",
      "Dimension of a word vector: 300\n",
      "Vector components of a word: [ 1.0730e-01  8.9000e-03  6.0000e-04  5.5000e-03 -6.4600e-02 -6.0000e-02\n",
      "  4.5000e-02 -1.3300e-02 -3.5700e-02  4.3000e-02 -3.5600e-02 -3.2000e-03\n",
      "  7.3000e-03 -1.0000e-04  2.5800e-02 -1.6600e-02  7.5000e-03  6.8600e-02\n",
      "  3.9200e-02  7.5300e-02  1.1500e-02 -8.7000e-03  4.2100e-02  2.6500e-02\n",
      " -6.0100e-02  2.4200e-01  1.9900e-02 -7.3900e-02 -3.1000e-03 -2.6300e-02\n",
      " -6.2000e-03  1.6800e-02 -3.5700e-02 -2.4900e-02  1.9000e-02 -1.8400e-02\n",
      " -5.3700e-02  1.4200e-01  6.0000e-02  2.2600e-02 -3.8000e-03 -6.7500e-02\n",
      " -3.6000e-03 -8.0000e-03  5.7000e-02  2.0800e-02  2.2300e-02 -2.5600e-02\n",
      " -1.5300e-02  2.2000e-03 -4.8200e-02  1.3100e-02 -6.0160e-01 -8.8000e-03\n",
      "  1.0600e-02  2.2900e-02  3.3600e-02  7.1000e-03  8.8700e-02  2.3700e-02\n",
      " -2.9000e-02 -4.0500e-02 -1.2500e-02  1.4700e-02  4.7500e-02  6.4700e-02\n",
      "  4.7400e-02  1.9900e-02  4.0800e-02  3.2200e-02  3.6000e-03  3.5000e-02\n",
      " -7.2300e-02 -3.0500e-02  1.8400e-02 -2.6000e-03  2.4000e-02 -1.6000e-02\n",
      " -3.0800e-02  4.3400e-02  1.4700e-02 -4.5700e-02 -2.6700e-02 -1.7030e-01\n",
      " -9.9000e-03  4.1700e-02  2.3500e-02 -2.6000e-02 -1.5190e-01 -1.1600e-02\n",
      " -3.0600e-02 -4.1300e-02  3.3000e-02  7.2300e-02  3.6500e-02 -1.0000e-04\n",
      "  4.2000e-03  3.4600e-02  2.7700e-02 -3.0500e-02  7.8400e-02 -4.0400e-02\n",
      "  1.8700e-02 -2.2500e-02 -2.0600e-02 -1.7900e-02 -2.4280e-01  6.6900e-02\n",
      "  5.2300e-02  5.2700e-02  1.4900e-02 -7.0800e-02 -9.8700e-02  2.6300e-02\n",
      " -6.1100e-02  3.0200e-02  2.1600e-02  3.1300e-02 -1.4000e-02 -2.4950e-01\n",
      " -3.4600e-02 -4.8000e-02  2.5000e-02  2.1300e-01 -3.3000e-02 -1.5530e-01\n",
      " -2.9200e-02 -3.4600e-02  1.0740e-01  1.0000e-03 -1.1700e-02 -5.7000e-03\n",
      " -1.2800e-01 -3.8000e-03  1.3000e-02 -1.1570e-01 -1.0800e-02  2.7500e-02\n",
      "  1.5800e-02 -1.6900e-02  7.0000e-03  2.4700e-02  5.1000e-02  1.0292e+00\n",
      " -2.8300e-02 -3.1000e-02 -2.6000e-03 -3.4300e-02  5.7800e-02  4.4400e-02\n",
      "  8.1200e-02 -2.1100e-02 -8.7200e-02  1.6900e-02  4.9900e-02  4.8500e-02\n",
      "  2.2700e-02 -3.2300e-02 -3.5000e-03  4.3500e-02 -2.7500e-02  1.5400e-02\n",
      "  1.3500e-02 -4.8400e-02 -6.9900e-02 -5.0200e-02  2.7450e-01 -3.0000e-04\n",
      " -3.7100e-02  5.1700e-02 -9.0800e-02  1.3000e-03  3.6000e-02  2.8000e-02\n",
      "  8.3900e-02  9.8000e-02 -4.9000e-02 -2.4230e-01 -1.4200e-02  2.4000e-03\n",
      " -2.0700e-02  1.2000e-03  8.8000e-03 -1.4300e-02 -1.9700e-02  5.1500e-02\n",
      " -8.5000e-03  2.5700e-02  2.1540e-01  3.0100e-02  2.1100e-02  5.3000e-02\n",
      " -5.0000e-04  1.7700e-02  1.6000e-03 -5.3000e-03 -1.6200e-02 -2.2300e-02\n",
      " -1.8620e-01  3.9800e-02  6.5800e-02 -9.6200e-02 -7.6000e-03 -7.5000e-03\n",
      " -3.4200e-02 -2.6500e-02  4.2000e-02  5.2200e-02 -2.6600e-02  2.0100e-02\n",
      " -1.3310e-01 -3.6700e-02  3.5100e-02  5.1800e-02 -8.7000e-03  5.9900e-02\n",
      " -1.0860e-01 -1.8800e-02  4.8100e-02  1.0500e-02 -6.0000e-03  1.5100e-02\n",
      " -3.1000e-03  7.7000e-03 -2.7600e-02 -3.7300e-02 -2.0300e-02  4.7200e-02\n",
      "  2.4600e-02  1.4400e-01  5.4200e-02 -2.2500e-02  2.4950e-01  1.6170e-01\n",
      "  3.8000e-03  1.1190e-01 -2.3000e-02 -7.8500e-02  2.5000e-02 -6.1600e-02\n",
      " -4.8500e-02  2.2500e-02  2.8100e-02  4.1000e-03  1.1200e-02  1.7200e-02\n",
      "  2.9100e-02 -2.8200e-02  2.6000e-03  4.0550e-01  3.9200e-02  8.8000e-03\n",
      "  2.2800e-02  2.9900e-02  1.1950e-01  5.4500e-02 -2.0000e-03  2.0000e-03\n",
      "  4.9000e-02  1.4500e-02 -8.6000e-03  9.8000e-03 -2.3600e-02  1.7100e-02\n",
      " -7.6500e-02 -4.0000e-02  1.2800e-02  1.1000e-03  4.2000e-03  2.4400e-02\n",
      "  7.5000e-03  2.0000e-02  2.0100e-02  1.9600e-02 -3.7700e-02 -4.3200e-02\n",
      " -7.3000e-03 -2.1000e-03  1.8300e-02  7.6000e-03  1.8050e-01 -5.5100e-02\n",
      "  7.5000e-03 -5.1600e-02  4.2000e-02 -6.8000e-03 -7.1100e-02 -1.4080e-01\n",
      "  5.0400e-02  2.7600e-02  4.7000e-02  3.2300e-02 -2.1900e-02  1.0000e-03\n",
      "  8.9000e-03  2.7600e-02  1.8600e-02  5.0000e-03  1.1730e-01 -4.0000e-02]\n",
      "Word: cars, Similarity: 0.80\n",
      "Word: automobile, Similarity: 0.77\n",
      "Word: vehicle, Similarity: 0.75\n",
      "Word: Car, Similarity: 0.72\n",
      "Word: truck, Similarity: 0.70\n",
      "Word: SUV, Similarity: 0.69\n",
      "Word: automobiles, Similarity: 0.68\n",
      "Word: dealership, Similarity: 0.67\n",
      "Word: garage, Similarity: 0.67\n",
      "Word: driver, Similarity: 0.65\n"
     ]
    }
   ],
   "source": [
    "# Getting the tokens \n",
    "words = []\n",
    "for word in en_model.vocab:\n",
    "    words.append(word)\n",
    "\n",
    "# Printing out number of tokens available\n",
    "print(\"Number of Tokens: {}\".format(len(words)))\n",
    "\n",
    "# Printing out the dimension of a word vector \n",
    "print(\"Dimension of a word vector: {}\".format(\n",
    "    len(en_model[words[0]])\n",
    "))\n",
    "\n",
    "# Print out the vector of a word \n",
    "print(\"Vector components of a word: {}\".format(\n",
    "    en_model[words[0]]\n",
    "))\n",
    "\n",
    "# Pick a word \n",
    "find_similar_to = 'car'\n",
    "\n",
    "# Finding out similar words [default= top 10]\n",
    "for similar_word in en_model.similar_by_word(find_similar_to):\n",
    "    print(\"Word: {0}, Similarity: {1:.2f}\".format(\n",
    "        similar_word[0], similar_word[1]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNetwork2(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=600, out_features=300, bias=True)\n",
      "    (1): Dropout(p=0.3, inplace=False)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=300, out_features=80, bias=True)\n",
      "    (4): Dropout(p=0.3, inplace=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=80, out_features=2, bias=True)\n",
      "    (7): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyNetwork2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # define the layers\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(600, 300),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 80),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # forward pass\n",
    "        x = nn.ReLU(self.layers(x))\n",
    "        return x\n",
    "\n",
    "# instantiate the model\n",
    "model = MyNetwork2()\n",
    "\n",
    "# print model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the loss function\n",
    "criterion = torch.nn.MSELoss()\n",
    "# Construct the optimizer (Stochastic Gradient Descent in this case)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cars', 0.8045914769172668),\n",
       " ('automobile', 0.766738772392273),\n",
       " ('vehicle', 0.7534860372543335),\n",
       " ('Car', 0.717795193195343),\n",
       " ('truck', 0.6989946961402893),\n",
       " ('SUV', 0.689612865447998),\n",
       " ('automobiles', 0.6783527731895447),\n",
       " ('dealership', 0.6682884097099304),\n",
       " ('garage', 0.6681075692176819),\n",
       " ('driver', 0.6541328430175781)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_model.most_similar('car')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-a9f8a78cab51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-0eac6c847006>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0;34m-\u001b[0m \u001b[0mOutput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0m_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \"\"\"\n\u001b[0;32m-> 1368\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "y_pred = model(df_dev.iloc[0]['Text'])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert them to numpy arrays\n",
    "X_train = np.asarray(X)\n",
    "Y_train = np.asarray(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gradient Descent\n",
    "for epoch in range(20):\n",
    "   # Forward pass: Compute predicted y by passing x to the model\n",
    "   y_pred = model(x)\n",
    "\n",
    "   # Compute and print loss\n",
    "   loss = criterion(y_pred, y)\n",
    "   print('epoch: ', epoch,' loss: ', loss.item())\n",
    "\n",
    "   # Zero gradients, perform a backward pass, and update the weights.\n",
    "   optimizer.zero_grad()\n",
    "\n",
    "   # perform a backward pass (backpropagation)\n",
    "   loss.backward()\n",
    "\n",
    "   # Update the parameters\n",
    "   optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
